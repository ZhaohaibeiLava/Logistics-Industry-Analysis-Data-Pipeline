{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c61da3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Cell 0: 【⚠️【每次运行时请在此处配置】\n",
    "# --------------------------------------------------\n",
    "# --- 定义当前需要归档的年月 ---\n",
    "ARCHIVE_YEAR = 2024\n",
    "ARCHIVE_MONTH = 9\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92db63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Cell 1: 执行所有数据的归档\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc0a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入完成。\n",
      "路径设置完毕，将开始归档 2024年9月 的数据。\n",
      "\n",
      "===== 开始执行 2024 年 9 月的数据归档任务 =====\n",
      "--- 开始归档 anjian_data 数据至 2024-09 ---\n",
      "  - 正在使用模式 '2024年9月' 筛选文件...\n",
      "  - 正在读取: 2024年9月极兔抽样.xlsx\n",
      "  - 正在读取: 2024年9月德邦抽样.xlsx\n",
      "  - 正在读取: 2024年9月京东抽样.xlsx\n",
      "  - 正在读取: 2024年9月韵达抽样.xlsx\n",
      "  - 正在读取: 2024年9月EMS抽样.xlsx\n",
      "  - 正在读取: 2024年9月顺丰抽样.xlsx\n",
      "  - 正在读取: 2024年9月中通抽样.xlsx\n",
      "  - 正在读取: 2024年9月邮政抽样.xlsx\n",
      "  - 正在读取: 2024年9月圆通抽样.xlsx\n",
      "  - 正在读取: 2024年9月申通抽样.xlsx\n",
      "  - 成功合并 10 个文件，共 707869 行数据。\n",
      "  - 正在强制转换列 '单号' 的类型为字符串...\n",
      "  - 正在强制转换列 '派送时间' 的类型为字符串...\n",
      "  - 正在写入数据到文件: /Users/lava/Documents/国家邮政局发展研究中心实习/python_data_analysis/报告数据/database/anjian_data/year=2024/month=9_temp/data.parquet\n",
      "  - 临时写入成功，准备替换正式目录...\n",
      "✅ 成功归档 anjian_data 数据！\n",
      "--- 开始归档 zhuzhuyun_merged_data 数据至 2024-09 ---\n",
      "  - 正在使用模式 '_202409' 筛选文件...\n",
      "  - 正在读取: 圆通_202409.xlsx\n",
      "  - 正在读取: 顺丰_202409.xlsx\n",
      "  - 正在读取: 申通_202409.xlsx\n",
      "  - 正在读取: 德邦_202409.xlsx\n",
      "  - 正在读取: 韵达_202409.xlsx\n",
      "  - 正在读取: 邮政_202409.xlsx\n",
      "  - 正在读取: 京东_202409.xlsx\n",
      "  - 正在读取: 极兔_202409.xlsx\n",
      "  - 正在读取: 中通_202409.xlsx\n",
      "  - 正在读取: EMS_202409.xlsx\n",
      "  - 成功合并 10 个文件，共 634507 行数据。\n",
      "  - 正在强制转换列 '快递单号' 的类型为字符串...\n",
      "  - 正在写入数据到文件: /Users/lava/Documents/国家邮政局发展研究中心实习/python_data_analysis/报告数据/database/zhuzhuyun_merged_data/year=2024/month=9_temp/data.parquet\n",
      "❌ 写入临时目录失败: (\"Could not convert '[QZ0]5' with type str: tried to convert to int64\", 'Conversion failed for column 任务备注 with type object')\n",
      "--- 开始归档 logistics_data 数据至 2024-09 ---\n",
      "  - 正在使用模式 '_202409' 筛选文件...\n",
      "  - 正在读取: 韵达_logistics_data_202409.xlsx\n",
      "  - 正在读取: 京东_logistics_data_202409.xlsx\n",
      "  - 正在读取: 极兔_logistics_data_202409.xlsx\n",
      "  - 正在读取: 顺丰_logistics_data_202409.xlsx\n",
      "  - 正在读取: 申通_logistics_data_202409.xlsx\n",
      "  - 正在读取: 圆通_logistics_data_202409.xlsx\n",
      "  - 正在读取: 邮政_logistics_data_202409.xlsx\n",
      "  - 正在读取: EMS_logistics_data_202409.xlsx\n",
      "  - 正在读取: 中通_logistics_data_202409.xlsx\n",
      "  - 正在读取: 德邦_logistics_data_202409.xlsx\n",
      "  - 成功合并 10 个文件，共 707858 行数据。\n",
      "  - 正在强制转换列 '单号' 的类型为字符串...\n",
      "  - 正在强制转换列 '派送时间' 的类型为字符串...\n",
      "  - 正在写入数据到文件: /Users/lava/Documents/国家邮政局发展研究中心实习/python_data_analysis/报告数据/database/logistics_data/year=2024/month=9_temp/data.parquet\n",
      "  - 临时写入成功，准备替换正式目录...\n",
      "✅ 成功归档 logistics_data 数据！\n",
      "--- 开始归档 transit_data 数据至 2024-09 ---\n",
      "  - 正在使用模式 '_202409' 筛选文件...\n",
      "  - 正在读取: 德邦_transit_data_202409.xlsx\n",
      "  - 正在读取: 中通_transit_data_202409.xlsx\n",
      "  - 正在读取: 韵达_transit_data_202409.xlsx\n",
      "  - 正在读取: EMS_transit_data_202409.xlsx\n",
      "  - 正在读取: 圆通_transit_data_202409.xlsx\n",
      "  - 正在读取: 极兔_transit_data_202409.xlsx\n",
      "  - 正在读取: 京东_transit_data_202409.xlsx\n",
      "  - 正在读取: 申通_transit_data_202409.xlsx\n",
      "  - 正在读取: 邮政_transit_data_202409.xlsx\n",
      "  - 成功合并 9 个文件，共 22040 行数据。\n",
      "  - 正在写入数据到文件: /Users/lava/Documents/国家邮政局发展研究中心实习/python_data_analysis/报告数据/database/transit_data/year=2024/month=9_temp/data.parquet\n",
      "  - 临时写入成功，准备替换正式目录...\n",
      "✅ 成功归档 transit_data 数据！\n",
      "--- 开始归档 data_analysis_result 数据至 2024-09 ---\n",
      "  - 正在使用模式 '_202409' 筛选文件...\n",
      "  - 正在读取: 中通_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 韵达_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 京东_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 邮政_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 顺丰_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 德邦_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 极兔_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 申通_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: EMS_data_analysis_result_202409.xlsx\n",
      "  - 正在读取: 圆通_data_analysis_result_202409.xlsx\n",
      "  - 成功合并 10 个文件，共 80 行数据。\n",
      "  - 正在写入数据到文件: /Users/lava/Documents/国家邮政局发展研究中心实习/python_data_analysis/报告数据/database/data_analysis_result/year=2024/month=9_temp/data.parquet\n",
      "  - 临时写入成功，准备替换正式目录...\n",
      "✅ 成功归档 data_analysis_result 数据！\n",
      "\n",
      "===== 所有归档任务执行完毕 =====\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "print(\"库导入完成。\")\n",
    "\n",
    "# --- 项目路径设置 ---\n",
    "base_path = Path.cwd()\n",
    "report_path = base_path / \"报告数据\"\n",
    "temp_path = report_path / \"temp\"\n",
    "\n",
    "# 源数据路径\n",
    "anjian_data_path = report_path / \"输入\" / \"安监数据\"\n",
    "zhuzhuyun_merge_path = temp_path / \"3_猪猪云合并数据\"\n",
    "logistics_data_path = temp_path / \"4_logistics数据\"\n",
    "transit_data_path = temp_path / \"5_中转数据\"\n",
    "data_analysis_result_path = report_path / \"输出\" / \"data_analysis_result\"\n",
    "data_analysis_result_path.mkdir(exist_ok=True)  # 确保目录存在\n",
    "\n",
    "# --- 目标数据库路径 ---\n",
    "db_path = report_path / \"database\"\n",
    "db_path.mkdir(exist_ok=True)\n",
    "print(f\"路径设置完毕，将开始归档 {ARCHIVE_YEAR}年{ARCHIVE_MONTH}月 的数据。\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 定义归档函数\n",
    "# --------------------------------------------------\n",
    "def archive_data_safely(\n",
    "    source_path: Path,\n",
    "    table_name: str,\n",
    "    db_base_path: Path,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    date_pattern_in_filename: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    将数据归档至Parquet数据库\n",
    "\n",
    "    :param source_path: 源文件夹路径。\n",
    "    :param table_name: 在数据库中对应的表名。\n",
    "    :param db_base_path: 数据库根路径。\n",
    "    :param year: 归档年份。\n",
    "    :param month: 归档月份。\n",
    "    :param date_pattern_in_filename: 用于在文件名中识别月份的独特字符串模式。\n",
    "    \"\"\"\n",
    "    print(f\"--- 开始归档 {table_name} 数据至 {year}-{month:02d} ---\")\n",
    "\n",
    "    if not source_path.exists():\n",
    "        print(f\"⚠️ 源目录不存在: {source_path}，跳过归档。\")\n",
    "        return\n",
    "\n",
    "    print(f\"  - 正在使用模式 '{date_pattern_in_filename}' 筛选文件...\")\n",
    "    all_files = list(source_path.glob(\"*.xlsx\"))\n",
    "    files_to_process = [f for f in all_files if date_pattern_in_filename in f.name]\n",
    "\n",
    "    if not files_to_process:\n",
    "        print(f\"✅ 在 {source_path} 中未找到匹配模式的文件，跳过归档。\")\n",
    "        return\n",
    "\n",
    "    df_list = []\n",
    "    for f in files_to_process:\n",
    "        print(f\"  - 正在读取: {f.name}\")\n",
    "        df_list.append(pd.read_excel(f, engine=\"openpyxl\"))\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"❌ 未能加载任何数据，归档中止。\")\n",
    "        return\n",
    "\n",
    "    full_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"  - 成功合并 {len(files_to_process)} 个文件，共 {len(full_df)} 行数据。\")\n",
    "\n",
    "    # --- 【核心修正】开始：将'任务备注'添加到列表中 ---\n",
    "    problematic_columns = [\"单号\", \"快递单号\", \"派送时间\", \"任务备注\"]\n",
    "    for col in problematic_columns:\n",
    "        if col in full_df.columns:\n",
    "            print(f\"  - 正在强制转换列 '{col}' 的类型为字符串...\")\n",
    "            full_df[col] = full_df[col].astype(str)\n",
    "    # --- 【核心修正】结束 ---\n",
    "\n",
    "    full_df[\"year\"] = year\n",
    "    full_df[\"month\"] = month\n",
    "\n",
    "    output_table_path = db_path / table_name\n",
    "    final_partition_path = output_table_path / f\"year={year}\" / f\"month={month}\"\n",
    "    temp_partition_path = output_table_path / f\"year={year}\" / f\"month={month}_temp\"\n",
    "\n",
    "    temp_partition_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        output_file_path = temp_partition_path / \"data.parquet\"\n",
    "        print(f\"  - 正在写入数据到文件: {output_file_path}\")\n",
    "        full_df.to_parquet(output_file_path, engine=\"pyarrow\", index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 写入临时目录失败: {e}\")\n",
    "        if temp_partition_path.exists():\n",
    "            shutil.rmtree(temp_partition_path)\n",
    "        return\n",
    "\n",
    "    print(\"  - 临时写入成功，准备替换正式目录...\")\n",
    "    if final_partition_path.exists():\n",
    "        print(f\"  - 发现旧目录，正在删除: {final_partition_path}\")\n",
    "        shutil.rmtree(final_partition_path)\n",
    "\n",
    "    os.rename(temp_partition_path, final_partition_path)\n",
    "    print(f\"✅ 成功归档 {table_name} 数据！\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 执行所有数据的归档\n",
    "# --------------------------------------------------\n",
    "print(f\"\\n===== 开始执行 {ARCHIVE_YEAR} 年 {ARCHIVE_MONTH} 月的数据归档任务 =====\")\n",
    "\n",
    "# 为不同文件名规则定义日期匹配模式\n",
    "anjian_pattern = f\"{ARCHIVE_YEAR}年{ARCHIVE_MONTH}月\"\n",
    "common_pattern = f\"_{ARCHIVE_YEAR}{ARCHIVE_MONTH:02d}\"\n",
    "\n",
    "# 1. 归档 \"安监数据\"\n",
    "archive_data_safely(\n",
    "    anjian_data_path,\n",
    "    \"anjian_data\",\n",
    "    db_path,\n",
    "    ARCHIVE_YEAR,\n",
    "    ARCHIVE_MONTH,\n",
    "    date_pattern_in_filename=anjian_pattern,\n",
    ")\n",
    "\n",
    "# 2. 归档 \"3_猪猪云合并数据\"\n",
    "archive_data_safely(\n",
    "    zhuzhuyun_merge_path,\n",
    "    \"zhuzhuyun_merged_data\",\n",
    "    db_path,\n",
    "    ARCHIVE_YEAR,\n",
    "    ARCHIVE_MONTH,\n",
    "    date_pattern_in_filename=common_pattern,\n",
    ")\n",
    "\n",
    "# 3. 归档 \"4_logistics数据\"\n",
    "archive_data_safely(\n",
    "    logistics_data_path,\n",
    "    \"logistics_data\",\n",
    "    db_path,\n",
    "    ARCHIVE_YEAR,\n",
    "    ARCHIVE_MONTH,\n",
    "    date_pattern_in_filename=common_pattern,\n",
    ")\n",
    "\n",
    "# 4. 归档 \"5_中转数据\"\n",
    "archive_data_safely(\n",
    "    transit_data_path,\n",
    "    \"transit_data\",\n",
    "    db_path,\n",
    "    ARCHIVE_YEAR,\n",
    "    ARCHIVE_MONTH,\n",
    "    date_pattern_in_filename=common_pattern,\n",
    ")\n",
    "\n",
    "# 5. 归档 \"data_analysis_result\"\n",
    "archive_data_safely(\n",
    "    data_analysis_result_path,\n",
    "    \"data_analysis_result\",\n",
    "    db_path,\n",
    "    ARCHIVE_YEAR,\n",
    "    ARCHIVE_MONTH,\n",
    "    date_pattern_in_filename=common_pattern,\n",
    ")\n",
    "\n",
    "print(\"\\n===== 所有归档任务执行完毕 =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37452e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 开始执行【增强版】数据验证 =====\n",
      "\n",
      "[1/3] 正在验证 'anjian_data'...\n",
      "✅ 'anjian_data' 表 2025-06 的总行数为: 781973 行。\n",
      "  - (请与 Cell 3 输出的 '成功合并' 行数对比，应一致)\n",
      "\n",
      "[2/3] 正在验证 'zhuzhuyun_merged_data'...\n",
      "✅ 'zhuzhuyun_merged_data' 表数据抽样成功:\n",
      "              快递单号 快递公司                 揽收时间                 最新时间     时效  \\\n",
      "0  777314022551584   申通  2025-06-09 13:03:38  2025-06-14 16:56:54  124小时   \n",
      "1  776103484916314   申通  2025-06-09 17:41:19  2025-06-14 23:51:25  127小时   \n",
      "2  773360013887328   申通  2025-06-09 20:51:03  2025-06-14 20:50:44  120小时   \n",
      "3  773360177148225   申通  2025-06-09 18:16:44  2025-06-11 21:42:39   52小时   \n",
      "4  777313398347326   申通  2025-06-09 16:25:36  2025-06-11 08:43:25   41小时   \n",
      "\n",
      "    发出至今   最新至今  条数                                           最后1条物流信息 物流状态  \\\n",
      "0  445小时  321小时  12  【驿站】包裹已签收！如有问题请联系：代收点13321544018，您的快递已经妥投，投诉电话...  已签收   \n",
      "1  440小时  314小时  12  您的快件已由【门口】签收，如有疑问请联系派件员：13927019001，有事先呼叫我，勿找平...  已签收   \n",
      "2  437小时  317小时  12  您的快件已由【西陇大队驿站代签收】签收，如有疑问请联系派件员：17825286652，有事先...  已签收   \n",
      "3  439小时  388小时  10  【自提柜】包裹已签收！如有问题请联系派件员：13717638590，您的快递已经妥投，投诉电...  已签收   \n",
      "4  441小时  401小时   9  您的快件已由【门口】签收，如有疑问请联系派件员：17331999978，有事先呼叫我，勿找平...  已签收   \n",
      "\n",
      "                  查询时间                                             完整物流信息  \\\n",
      "0  2025-06-28 01:06:20  2025-06-14 16:56:54 | 【驿站】包裹已签收！如有问题请联系：代收点133...   \n",
      "1  2025-06-28 01:06:22  2025-06-14 23:51:25 | 您的快件已由【门口】签收，如有疑问请联系派件员：...   \n",
      "2  2025-06-28 01:05:44  2025-06-14 20:50:44 | 您的快件已由【西陇大队驿站代签收】签收，如有疑问...   \n",
      "3  2025-06-28 01:06:20  2025-06-11 21:42:39 | 【自提柜】包裹已签收！如有问题请联系派件员：13...   \n",
      "4  2025-06-28 01:06:02  2025-06-11 08:43:25 | 您的快件已由【门口】签收，如有疑问请联系派件员：...   \n",
      "\n",
      "   订单编号                                          倒数第2条物流信息  \\\n",
      "0   NaN  您的包裹已放入福利小区服务部，请您尽快前往福利小区1栋菜鸟驿站领取您的包裹，如有疑问请联系：...   \n",
      "1   NaN  【揭阳市】广东揭阳新亨镇一服务点 的快递员(徐炜/13927019001)正在为您派送(有事...   \n",
      "2   NaN  【揭阳市】广东普宁西陇营业部 的快递员(杜楷铨/17825286652)正在为您派送(有事呼...   \n",
      "3   NaN  【自提柜】您的包裹已存放至丰巢智能柜，记得来北京市朝阳区弘文公寓正门丰巢柜取它回家！如有取件...   \n",
      "4   NaN  【北京市】北京朝阳区小营公司 的快递员(业郭晓松/17331999978)正在为您派送(有事...   \n",
      "\n",
      "                                             第1条物流信息 任务备注  手机尾号  无物流原因  year  \\\n",
      "0  【兰州市】甘肃兰州城关区东部凤凰公司(09314648149)的出港张崇和(15000407...   --  ----    NaN  2025   \n",
      "1  【拉萨市】西藏拉萨柳梧新区营业部(0891-6640112)的黄丽(17620176693)...   --  ----    NaN  2025   \n",
      "2  【拉萨市】西藏拉萨柳梧新区营业部(0891-6640112)的柳梧2(18108907986...   --  ----    NaN  2025   \n",
      "3  【西安市】陕西西安鄠邑区公司(02985791326)的陕西户县申通(18291495023...   --  ----    NaN  2025   \n",
      "4  【西安市】陕西西安碑林区兴庆公司(029-38054108)的代派送货勿催(13259946...   --  ----    NaN  2025   \n",
      "\n",
      "   month  \n",
      "0      6  \n",
      "1      6  \n",
      "2      6  \n",
      "3      6  \n",
      "4      6  \n",
      "\n",
      "  - 抽样数据类型信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 20 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   快递单号       5 non-null      object \n",
      " 1   快递公司       5 non-null      object \n",
      " 2   揽收时间       5 non-null      object \n",
      " 3   最新时间       5 non-null      object \n",
      " 4   时效         5 non-null      object \n",
      " 5   发出至今       5 non-null      object \n",
      " 6   最新至今       5 non-null      object \n",
      " 7   条数         5 non-null      int64  \n",
      " 8   最后1条物流信息   5 non-null      object \n",
      " 9   物流状态       5 non-null      object \n",
      " 10  查询时间       5 non-null      object \n",
      " 11  完整物流信息     5 non-null      object \n",
      " 12  订单编号       0 non-null      float64\n",
      " 13  倒数第2条物流信息  5 non-null      object \n",
      " 14  第1条物流信息    5 non-null      object \n",
      " 15  任务备注       5 non-null      object \n",
      " 16  手机尾号       5 non-null      object \n",
      " 17  无物流原因      0 non-null      float64\n",
      " 18  year       5 non-null      int64  \n",
      " 19  month      5 non-null      int64  \n",
      "dtypes: float64(2), int64(3), object(15)\n",
      "memory usage: 932.0+ bytes\n",
      "  - (请检查 '快递单号' 列的 Dtype 是否为 object 或 string)\n",
      "\n",
      "[3/3] 正在验证 'logistics_data'...\n",
      "✅ 'logistics_data' 表按 '企业' 列分组统计成功:\n",
      "    企业  row_count\n",
      "0   顺丰      83269\n",
      "1   中通      83160\n",
      "2   申通      83029\n",
      "3   圆通      82733\n",
      "4   韵达      81797\n",
      "5   极兔      81703\n",
      "6   邮政      81571\n",
      "7   京东      79688\n",
      "8   德邦      78551\n",
      "9  EMS      43390\n",
      "\n",
      "===== 数据验证执行完毕 =====\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Cell 2: 验证归档数据\n",
    "# --------------------------------------------------\n",
    "print(\"\\n===== 开始执行【增强版】数据验证 =====\")\n",
    "con = duckdb.connect()\n",
    "\n",
    "# ---- 验证参数 ----\n",
    "# 确保这里的年月和您归档的年月一致\n",
    "VERIFY_YEAR = ARCHIVE_YEAR\n",
    "VERIFY_MONTH = ARCHIVE_MONTH\n",
    "\n",
    "# --- 验证查询 1: 核对 anjian_data 的总行数 ---\n",
    "try:\n",
    "    print(\"\\n[1/3] 正在验证 'anjian_data'...\")\n",
    "    table_path = str(db_path / \"anjian_data\")\n",
    "    count = con.execute(f\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM read_parquet('{table_path}/*/*/*.parquet') \n",
    "        WHERE year={VERIFY_YEAR} AND month={VERIFY_MONTH}\n",
    "    \"\"\").fetchone()[0]\n",
    "\n",
    "    print(\n",
    "        f\"✅ 'anjian_data' 表 {VERIFY_YEAR}-{VERIFY_MONTH:02d} 的总行数为: {count} 行。\"\n",
    "    )\n",
    "    print(\"  - (请与 Cell 3 输出的 '成功合并' 行数对比，应一致)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 'anjian_data' 验证失败: {e}\")\n",
    "\n",
    "# --- 验证查询 2: 抽样检查 zhuzhuyun_merged_data 的数据和类型 ---\n",
    "try:\n",
    "    print(\"\\n[2/3] 正在验证 'zhuzhuyun_merged_data'...\")\n",
    "    table_path = str(db_path / \"zhuzhuyun_merged_data\")\n",
    "    sample_df = con.execute(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM read_parquet('{table_path}/*/*/*.parquet') \n",
    "        WHERE year={VERIFY_YEAR} AND month={VERIFY_MONTH}\n",
    "        LIMIT 5\n",
    "    \"\"\").df()\n",
    "\n",
    "    print(f\"✅ 'zhuzhuyun_merged_data' 表数据抽样成功:\")\n",
    "    print(sample_df)\n",
    "    print(\"\\n  - 抽样数据类型信息:\")\n",
    "    sample_df.info()\n",
    "    print(\"  - (请检查 '快递单号' 列的 Dtype 是否为 object 或 string)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 'zhuzhuyun_merged_data' 验证失败: {e}\")\n",
    "\n",
    "# --- 验证查询 3: 按公司分组统计 logistics_data 行数 ---\n",
    "try:\n",
    "    print(\"\\n[3/3] 正在验证 'logistics_data'...\")\n",
    "    table_path = str(db_path / \"logistics_data\")\n",
    "    company_col_name = \"企业\"\n",
    "\n",
    "    # 首先检查'企业'列是否存在\n",
    "    all_columns = (\n",
    "        con.execute(\n",
    "            f\"DESCRIBE SELECT * FROM read_parquet('{table_path}/*/*/*.parquet')\"\n",
    "        )\n",
    "        .df()[\"column_name\"]\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    if company_col_name in all_columns:\n",
    "        grouped_df = con.execute(f\"\"\"\n",
    "            SELECT \"{company_col_name}\", COUNT(*) as row_count\n",
    "            FROM read_parquet('{table_path}/*/*/*.parquet') \n",
    "            WHERE year={VERIFY_YEAR} AND month={VERIFY_MONTH}\n",
    "            GROUP BY \"{company_col_name}\"\n",
    "            ORDER BY row_count DESC\n",
    "        \"\"\").df()\n",
    "\n",
    "        print(f\"✅ 'logistics_data' 表按 '{company_col_name}' 列分组统计成功:\")\n",
    "        print(grouped_df)\n",
    "    else:\n",
    "        print(\n",
    "            f\"⚠️ 在 'logistics_data' 表中未找到列 '{company_col_name}'，跳过分组验证。\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 'logistics_data' 验证失败: {e}\")\n",
    "\n",
    "print(\"\\n===== 数据验证执行完毕 =====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
