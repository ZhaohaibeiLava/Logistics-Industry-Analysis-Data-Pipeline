{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49283ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Cell 1: å¯¼å…¥åº“å¹¶è®¾ç½®é¡¹ç›®ç»“æ„\n",
    "# --------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "base_path = Path.cwd()\n",
    "report_path = base_path / \"æŠ¥å‘Šæ•°æ®\"\n",
    "# è¾“å…¥è·¯å¾„\n",
    "input_path = report_path / \"è¾“å…¥\"\n",
    "anjian_data_path = input_path / \"å®‰ç›‘æ•°æ®\"\n",
    "base_data_path = input_path / \"basic_data.xlsx\"\n",
    "# è¾“å‡ºè·¯å¾„\n",
    "output_path = report_path / \"è¾“å‡º\"\n",
    "# ä¸­é—´è¿‡ç¨‹æ–‡ä»¶è·¯å¾„ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼Œç”¨äºå­˜æ”¾ä¸´æ—¶æ–‡ä»¶ï¼‰\n",
    "temp_path = report_path / \"temp\"\n",
    "upload_split_path = temp_path / \"1_å¾…ä¸Šä¼ çŒªçŒªäº‘æ–‡ä»¶\"\n",
    "zhuzhuyun_download_path = temp_path / \"2_çŒªçŒªäº‘ä¸‹è½½æ•°æ®\"\n",
    "zhuzhuyun_merge_path = temp_path / \"3_çŒªçŒªäº‘åˆå¹¶æ•°æ®\"\n",
    "pycharm_input_path = temp_path / \"4_logisticsæ•°æ®\"\n",
    "transit_data_path = temp_path / \"5_ä¸­è½¬æ•°æ®\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb67a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. æŠ¥å‘Šå‘¨æœŸé…ç½®ï¼ˆæ¯æœˆä»…ä¿®æ”¹æ­¤å¤„ï¼‰ ---\n",
    "CURRENT_YEAR_MONTH = \"202506\"\n",
    "PREVIOUS_YEAR_MONTH = \"202505\"\n",
    "LAST_YEAR_MONTH = \"202406\"\n",
    "CURRENT_MONTH_DISPLAY = f\"{int(CURRENT_YEAR_MONTH[-2:])}æœˆ\"  # æ— éœ€ä¿®æ”¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ce982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹ç”Ÿæˆ 202506 æœˆåº¦ä¸­é€šæŠ¥å‘Š...\n",
      "\n",
      "æ­£åœ¨ä» 'basic_data.xlsx' åŠ è½½ Top 30 åŸå¸‚åˆ—è¡¨...\n",
      "æˆåŠŸåŠ è½½ 30 ä¸ª Top 30 åŸå¸‚ã€‚\n",
      "\n",
      "--- æ­£åœ¨å¤„ç† æœ¬æœŸ æ•°æ® ---\n",
      "  âœ… æœ¬æœŸ æ•°æ®æå–å®Œæˆã€‚\n",
      "\n",
      "--- æ­£åœ¨å¤„ç† ä¸Šæœˆ æ•°æ® ---\n",
      "  âœ… ä¸Šæœˆ æ•°æ®æå–å®Œæˆã€‚\n",
      "\n",
      "--- æ­£åœ¨å¤„ç† å»å¹´åŒæœŸ æ•°æ® ---\n",
      "  âœ… å»å¹´åŒæœŸ æ•°æ®æå–å®Œæˆã€‚\n",
      "\n",
      "ğŸ‰ æœ€ç»ˆæŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: /Users/lava/Documents/å›½å®¶é‚®æ”¿å±€å‘å±•ç ”ç©¶ä¸­å¿ƒå®ä¹ /python_data_analysis/æŠ¥å‘Šæ•°æ®/è¾“å‡º/2_ä¸­é€šæŠ¥å‘Šè¡¨æ ¼/ä¸­é€šæŠ¥å‘Šæ•°æ®_202506.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 2: ä¸­é€šæŠ¥å‘Šæ‰€éœ€è¡¨æ ¼ç”Ÿæˆ\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. è·¯å¾„å’Œå¸¸é‡å®šä¹‰ ---\n",
    "ROOT_PATH = Path.cwd()\n",
    "OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"2_ä¸­é€šæŠ¥å‘Šè¡¨æ ¼\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASIC_DATA_FILE = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å…¥\" / \"basic_data.xlsx\"\n",
    "\n",
    "\n",
    "def get_file_paths(period_label):\n",
    "    base_dir_map = {\n",
    "        \"æœ¬æœŸ\": ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"data_analysis_result\",\n",
    "        \"ä¸Šæœˆ\": ROOT_PATH\n",
    "        / \"æŠ¥å‘Šæ•°æ®\"\n",
    "        / \"è¾“å…¥\"\n",
    "        / \"historical_data\"\n",
    "        / f\"{PREVIOUS_YEAR_MONTH}\"\n",
    "        / f\"data_analysis_result_{PREVIOUS_YEAR_MONTH}\",\n",
    "        \"å»å¹´åŒæœŸ\": ROOT_PATH\n",
    "        / \"æŠ¥å‘Šæ•°æ®\"\n",
    "        / \"è¾“å…¥\"\n",
    "        / \"historical_data\"\n",
    "        / f\"{LAST_YEAR_MONTH}\"\n",
    "        / f\"data_analysis_result_{LAST_YEAR_MONTH}\",\n",
    "    }\n",
    "    path = base_dir_map.get(period_label)\n",
    "    if period_label != \"æœ¬æœŸ\" and (not path or not path.exists()):\n",
    "        month_var = PREVIOUS_YEAR_MONTH if period_label == \"ä¸Šæœˆ\" else LAST_YEAR_MONTH\n",
    "        print(f\"  - âš ï¸ è­¦å‘Š: è·¯å¾„ {path} ä¸å­˜åœ¨ï¼Œå°è¯•å›é€€åˆ°æ—§çš„'åˆ†ææ€»æŠ¥å‘Š'æ–‡ä»¶...\")\n",
    "        return {\n",
    "            \"report\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / month_var\n",
    "            / f\"åˆ†ææ€»æŠ¥å‘Š_{month_var}.xlsx\"\n",
    "        }\n",
    "    return {\"data_analysis\": path} if path else {}\n",
    "\n",
    "\n",
    "# æ˜ç¡®å®šä¹‰å„ä¸ªå…¬å¸åˆ—è¡¨çš„ç”¨é€”\n",
    "COMPANIES_ALL = [\n",
    "    \"ä¸­é€š\",\n",
    "    \"åœ†é€š\",\n",
    "    \"æå…”\",\n",
    "    \"ç”³é€š\",\n",
    "    \"éŸµè¾¾\",\n",
    "    \"é¡ºä¸°\",\n",
    "    \"äº¬ä¸œ\",\n",
    "    \"EMS\",\n",
    "    \"å¾·é‚¦\",\n",
    "    \"å¿«åŒ…\",\n",
    "]\n",
    "# ç”¨äºè¡Œä¸šå¯¹æ¯”çš„å…¬å¸åˆ—è¡¨ï¼Œæ˜ç¡®æ’é™¤'å¿«åŒ…'\n",
    "COMPANIES_FOR_INDUSTRY_COMPARISON = [c for c in COMPANIES_ALL if c != \"å¿«åŒ…\"]\n",
    "COMPANY_FILE_MAP = {\n",
    "    \"ä¸­é€š\": \"ä¸­é€š\",\n",
    "    \"åœ†é€š\": \"åœ†é€š\",\n",
    "    \"æå…”\": \"æå…”\",\n",
    "    \"ç”³é€š\": \"ç”³é€š\",\n",
    "    \"éŸµè¾¾\": \"éŸµè¾¾\",\n",
    "    \"é¡ºä¸°\": \"é¡ºä¸°\",\n",
    "    \"äº¬ä¸œ\": \"äº¬ä¸œ\",\n",
    "    \"EMS\": \"EMS\",\n",
    "    \"å¾·é‚¦\": \"å¾·é‚¦\",\n",
    "    \"å¿«åŒ…\": \"é‚®æ”¿\",\n",
    "}\n",
    "COMPANIES_TONGDATU = [\"åœ†é€š\", \"ç”³é€š\", \"ä¸­é€š\", \"æå…”\", \"éŸµè¾¾\"]\n",
    "METRICS_TABLE1 = {\n",
    "    \"å…¨ç¨‹æ—¶é™ï¼ˆå°æ—¶ï¼‰\": \"å…¨ç¨‹æ—¶é™\",\n",
    "    \"72å°æ—¶å¦¥æŠ•ç‡\": \"72å°æ—¶å‡†æ—¶ç‡\",\n",
    "    \"48å°æ—¶å¦¥æŠ•ç‡\": \"48å°æ—¶å‡†æ—¶ç‡\",\n",
    "}\n",
    "METRICS_TABLE2 = {\n",
    "    \"å¯„å‡ºåœ°å¤„ç†æ—¶é™\": \"å¯„å‡ºåœ°å¤„ç†æ—¶é™\",\n",
    "    \"è¿è¾“æ—¶é™\": \"è¿è¾“æ—¶é™\",\n",
    "    \"å¯„è¾¾åœ°å¤„ç†æ—¶é™\": \"å¯„è¾¾åœ°å¤„ç†æ—¶é™\",\n",
    "    \"æŠ•é€’æ—¶é™\": \"æŠ•é€’æ—¶é™\",\n",
    "}\n",
    "ALL_METRICS = {**METRICS_TABLE1, **METRICS_TABLE2}\n",
    "HIGHER_IS_BETTER = [\"72å°æ—¶å¦¥æŠ•ç‡\", \"48å°æ—¶å¦¥æŠ•ç‡\"]\n",
    "\n",
    "\n",
    "def load_top_cities(file_path: Path) -> set:\n",
    "    sheet_name, column_name = \"30_top_volume_city_2024\", \"åŸå¸‚\"\n",
    "    print(f\"\\næ­£åœ¨ä» '{file_path.name}' åŠ è½½ Top 30 åŸå¸‚åˆ—è¡¨...\")\n",
    "    try:\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"åŸºç¡€æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}\")\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        if column_name not in df.columns:\n",
    "            raise ValueError(\n",
    "                f\"åœ¨Sheet '{sheet_name}' ä¸­æœªæ‰¾åˆ°åä¸º '{column_name}' çš„åˆ—ã€‚\"\n",
    "            )\n",
    "        cities_set = set(df[column_name].dropna().astype(str).str.strip().tolist())\n",
    "        if not cities_set:\n",
    "            print(f\"è­¦å‘Š: ä» '{file_path.name}' ä¸­åŠ è½½çš„åŸå¸‚åˆ—è¡¨ä¸ºç©ºã€‚\")\n",
    "        else:\n",
    "            print(f\"æˆåŠŸåŠ è½½ {len(cities_set)} ä¸ª Top 30 åŸå¸‚ã€‚\")\n",
    "        return cities_set\n",
    "    except Exception as e:\n",
    "        print(f\"é”™è¯¯: åŠ è½½Top 30åŸå¸‚åˆ—è¡¨å¤±è´¥ï¼é”™è¯¯ä¿¡æ¯: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Part 1: æ•°æ®è®¡ç®—ä¸æå–å¼•æ“\n",
    "# ==============================================================================\n",
    "def calculate_metrics_from_result_files(data_analysis_dir, top_30_cities):\n",
    "    df_result = pd.DataFrame()\n",
    "    if not data_analysis_dir or not data_analysis_dir.exists():\n",
    "        print(f\"  - âš ï¸ è­¦å‘Šï¼šæ•°æ®åˆ†æç»“æœç›®å½•ä¸å­˜åœ¨: {data_analysis_dir}\")\n",
    "        return df_result\n",
    "    for company_key, file_prefix in COMPANY_FILE_MAP.items():\n",
    "        file_path = data_analysis_dir / f\"{file_prefix}_data_analysis_result.xlsx\"\n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=\"çº¿è·¯è¯¦ç»†æ•°æ®\")\n",
    "            if df.empty:\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"  - âš ï¸ è­¦å‘Šï¼šè¯»å– {file_path.name} çš„ 'çº¿è·¯è¯¦ç»†æ•°æ®' sheetå¤±è´¥: {e}\")\n",
    "            continue\n",
    "\n",
    "        # è®¡ç®—é™¤48hå¦¥æŠ•ç‡å¤–çš„æ‰€æœ‰æŒ‡æ ‡\n",
    "        df[\"72å°æ—¶å‡†æ—¶ç‡\"] = df[\"å…¨ç¨‹æ—¶é™\"] <= 72\n",
    "        for report_metric, source_metric in ALL_METRICS.items():\n",
    "            if report_metric == \"48å°æ—¶å¦¥æŠ•ç‡\":\n",
    "                continue\n",
    "            if source_metric in df.columns:\n",
    "                df_result.loc[report_metric, company_key] = df[source_metric].mean()\n",
    "\n",
    "        # è®¡ç®—48å°æ—¶å¦¥æŠ•ç‡ (åŸºäºTop 30åŸå¸‚äº’å¯„æ•°æ®)\n",
    "        top_30_data = df[\n",
    "            (df[\"å¯„å‡ºåŸå¸‚\"].isin(top_30_cities)) & (df[\"å¯„è¾¾åŸå¸‚\"].isin(top_30_cities))\n",
    "        ]\n",
    "        rate_48h = (\n",
    "            (top_30_data[\"å…¨ç¨‹æ—¶é™\"] <= 48).mean() if not top_30_data.empty else 0.0\n",
    "        )\n",
    "        df_result.loc[\"48å°æ—¶å¦¥æŠ•ç‡\", company_key] = rate_48h\n",
    "    return df_result\n",
    "\n",
    "\n",
    "def get_period_data(period_label, top_30_cities):\n",
    "    print(f\"\\n--- æ­£åœ¨å¤„ç† {period_label} æ•°æ® ---\")\n",
    "    paths = get_file_paths(period_label)\n",
    "    data_analysis_dir = paths.get(\"data_analysis\")\n",
    "    df_final = calculate_metrics_from_result_files(data_analysis_dir, top_30_cities)\n",
    "\n",
    "    if df_final.empty:\n",
    "        # å…¼å®¹æ—§é€»è¾‘\n",
    "        report_file_path = paths.get(\"report\")\n",
    "        if report_file_path and report_file_path.exists():\n",
    "            print(\n",
    "                f\"  - âš ï¸ è­¦å‘Šï¼šåœ¨ {data_analysis_dir} æœªæ‰¾åˆ°æ•°æ®, å°è¯•ä»æ—§æŠ¥å‘Š {report_file_path.name} è¯»å–...\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"  - âš ï¸ è­¦å‘Šï¼š{period_label} æœªèƒ½è®¡ç®—å‡ºä»»ä½•æŒ‡æ ‡ï¼Œæ•°æ®æºç¼ºå¤±ã€‚\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "    industry_competitors = df_final.columns.intersection(\n",
    "        COMPANIES_FOR_INDUSTRY_COMPARISON\n",
    "    ).tolist()\n",
    "    if industry_competitors:\n",
    "        df_final[\"è¡Œä¸šå‡å€¼\"] = df_final[industry_competitors].mean(axis=1)\n",
    "        for metric, row in df_final.iterrows():\n",
    "            if metric in HIGHER_IS_BETTER:\n",
    "                df_final.loc[metric, \"è¡Œä¸šæœ€ä¼˜\"] = row[industry_competitors].max()\n",
    "            else:\n",
    "                df_final.loc[metric, \"è¡Œä¸šæœ€ä¼˜\"] = row[industry_competitors].min()\n",
    "\n",
    "    # è®¡ç®—é€šè¾¾å…”æŒ‡æ ‡\n",
    "    existing_tongdatu = df_final.columns.intersection(COMPANIES_TONGDATU).tolist()\n",
    "    if existing_tongdatu:\n",
    "        df_final[\"é€šè¾¾å…”å‡å€¼\"] = df_final[existing_tongdatu].mean(axis=1)\n",
    "        for metric, row in df_final.iterrows():\n",
    "            if metric in HIGHER_IS_BETTER:\n",
    "                df_final.loc[metric, \"é€šè¾¾å…”æœ€ä¼˜\"] = row[existing_tongdatu].max()\n",
    "            else:\n",
    "                df_final.loc[metric, \"é€šè¾¾å…”æœ€ä¼˜\"] = row[existing_tongdatu].min()\n",
    "\n",
    "    print(f\"  âœ… {period_label} æ•°æ®æå–å®Œæˆã€‚\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Part 2 & 3: æŠ¥å‘Šç”Ÿæˆä¸å†™å…¥å‡½æ•°\n",
    "# ==============================================================================\n",
    "def create_report_table(df_current, df_mom, df_yoy, metrics_dict):\n",
    "    report_cols = [\n",
    "        \"æŒ‡æ ‡\",\n",
    "        \"ç±»åˆ«\",\n",
    "        \"ä¸­é€š\",\n",
    "        \"é€šè¾¾å…”å‡å€¼\",\n",
    "        \"é€šè¾¾å…”æœ€ä¼˜\",\n",
    "        \"è¡Œä¸šå‡å€¼\",\n",
    "        \"è¡Œä¸šæœ€ä¼˜\",\n",
    "        \"æ’å\",\n",
    "    ]\n",
    "    value_cols = [\"ä¸­é€š\", \"é€šè¾¾å…”å‡å€¼\", \"é€šè¾¾å…”æœ€ä¼˜\", \"è¡Œä¸šå‡å€¼\", \"è¡Œä¸šæœ€ä¼˜\"]\n",
    "    if not df_mom.empty:\n",
    "        df_mom = df_mom.reindex(columns=df_current.columns)\n",
    "    if not df_yoy.empty:\n",
    "        df_yoy = df_yoy.reindex(columns=df_current.columns)\n",
    "    report_rows = [\n",
    "        f\"{metric}_{p}\" for metric in metrics_dict for p in [\"æœ¬æœŸ\", \"ç¯æ¯”\", \"åŒæ¯”\"]\n",
    "    ]\n",
    "    table_df = pd.DataFrame(index=report_rows, columns=report_cols).fillna(\"\")\n",
    "\n",
    "    for metric in metrics_dict.keys():\n",
    "        table_df.loc[f\"{metric}_æœ¬æœŸ\", \"æŒ‡æ ‡\"] = metric.replace(\"ï¼ˆå°æ—¶ï¼‰\", \"\")\n",
    "        table_df.loc[f\"{metric}_æœ¬æœŸ\", \"ç±»åˆ«\"] = CURRENT_MONTH_DISPLAY\n",
    "        table_df.loc[f\"{metric}_ç¯æ¯”\", \"ç±»åˆ«\"] = \"ç¯æ¯”\"\n",
    "        table_df.loc[f\"{metric}_åŒæ¯”\", \"ç±»åˆ«\"] = \"åŒæ¯”\"\n",
    "        if not df_current.empty and metric in df_current.index:\n",
    "            table_df.loc[f\"{metric}_æœ¬æœŸ\", value_cols] = df_current.loc[\n",
    "                metric, value_cols\n",
    "            ].values\n",
    "        if not df_mom.empty and metric in df_mom.index:\n",
    "            delta = df_current.loc[metric, value_cols] - df_mom.loc[metric, value_cols]\n",
    "            table_df.loc[f\"{metric}_ç¯æ¯”\", value_cols] = delta.round(4).values\n",
    "        if not df_yoy.empty and metric in df_yoy.index:\n",
    "            delta = df_current.loc[metric, value_cols] - df_yoy.loc[metric, value_cols]\n",
    "            table_df.loc[f\"{metric}_åŒæ¯”\", value_cols] = delta.round(4).values\n",
    "\n",
    "        ascending = metric not in HIGHER_IS_BETTER\n",
    "        # (ä¿®æ”¹) æ’åè®¡ç®—æ’é™¤'å¿«åŒ…'\n",
    "        if not df_current.empty and metric in df_current.index:\n",
    "            current_ranks = df_current.loc[\n",
    "                metric, COMPANIES_FOR_INDUSTRY_COMPARISON\n",
    "            ].rank(method=\"min\", ascending=ascending, na_option=\"bottom\")\n",
    "            table_df.loc[f\"{metric}_æœ¬æœŸ\", \"æ’å\"] = current_ranks.get(\"ä¸­é€š\")\n",
    "        if not df_mom.empty and metric in df_mom.index:\n",
    "            mom_ranks = df_mom.loc[metric, COMPANIES_FOR_INDUSTRY_COMPARISON].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_ç¯æ¯”\", \"æ’å\"] = mom_ranks.get(\"ä¸­é€š\")\n",
    "        if not df_yoy.empty and metric in df_yoy.index:\n",
    "            yoy_ranks = df_yoy.loc[metric, COMPANIES_FOR_INDUSTRY_COMPARISON].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_åŒæ¯”\", \"æ’å\"] = yoy_ranks.get(\"ä¸­é€š\")\n",
    "    return table_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def write_formatted_excel(writer, df, sheet_name, table_metrics_dict):\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    float_format = workbook.add_format({\"num_format\": \"0.00\"})\n",
    "    percent_format = workbook.add_format({\"num_format\": \"0.00%\"})\n",
    "    integer_format = workbook.add_format({\"num_format\": \"0\"})\n",
    "    rate_metrics_names = [metric for metric in table_metrics_dict if \"ç‡\" in metric]\n",
    "    for row_num in range(len(df)):\n",
    "        original_metric_name = list(table_metrics_dict.keys())[row_num // 3]\n",
    "        for col_num in range(2, 7):\n",
    "            cell_value = df.iloc[row_num, col_num]\n",
    "            if pd.isna(cell_value) or cell_value == \"\":\n",
    "                continue\n",
    "            if original_metric_name in rate_metrics_names:\n",
    "                worksheet.write_number(row_num + 1, col_num, cell_value, percent_format)\n",
    "            else:\n",
    "                worksheet.write_number(row_num + 1, col_num, cell_value, float_format)\n",
    "        rank_value = df.iloc[row_num, 7]\n",
    "        if pd.notna(rank_value) and isinstance(rank_value, (int, float)):\n",
    "            worksheet.write_number(row_num + 1, 7, rank_value, integer_format)\n",
    "    worksheet.set_column(\"A:A\", 18)\n",
    "    worksheet.set_column(\"B:B\", 8)\n",
    "    worksheet.set_column(\"C:H\", 12)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# æœ€ç»ˆæ‰§è¡Œå…¥å£\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # å‡è®¾è¿™äº›å˜é‡å·²åœ¨åˆ«å¤„å®šä¹‰ (ä½ éœ€è¦ç¡®ä¿å®ƒä»¬å­˜åœ¨)\n",
    "    # CURRENT_YEAR_MONTH, PREVIOUS_YEAR_MONTH, LAST_YEAR_MONTH, CURRENT_MONTH_DISPLAY\n",
    "\n",
    "    print(f\"ğŸš€ å¼€å§‹ç”Ÿæˆ {CURRENT_YEAR_MONTH} æœˆåº¦ä¸­é€šæŠ¥å‘Š...\")\n",
    "    top_30_cities = load_top_cities(BASIC_DATA_FILE)\n",
    "    df_current = get_period_data(\"æœ¬æœŸ\", top_30_cities)\n",
    "    df_mom = get_period_data(\"ä¸Šæœˆ\", top_30_cities)\n",
    "    df_yoy = get_period_data(\"å»å¹´åŒæœŸ\", top_30_cities)\n",
    "\n",
    "    if df_current.empty:\n",
    "        print(\"ğŸ›‘ æœ¬æœŸæ•°æ®æœªèƒ½æˆåŠŸæå–ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    table1_df = create_report_table(df_current, df_mom, df_yoy, METRICS_TABLE1)\n",
    "    table2_df = create_report_table(df_current, df_mom, df_yoy, METRICS_TABLE2)\n",
    "\n",
    "    output_path = OUTPUT_DIR / f\"ä¸­é€šæŠ¥å‘Šæ•°æ®_{CURRENT_YEAR_MONTH}.xlsx\"\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        write_formatted_excel(writer, table1_df, \"å…¨ç¨‹æ—¶é™åŠæ’å\", METRICS_TABLE1)\n",
    "        write_formatted_excel(writer, table2_df, \"åˆ†ç¯èŠ‚æ—¶é™åŠæ’å\", METRICS_TABLE2)\n",
    "\n",
    "    print(f\"\\nğŸ‰ æœ€ç»ˆæŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d4bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹ç”Ÿæˆ 202506 æœˆåº¦é‚®æ”¿æŠ¥å‘Š è¡¨1ï¼šå…¨ç¨‹æ—¶é™ã€72å°æ—¶å¦¥æŠ•ç‡åŠä¸­è½¬æ¬¡æ•°æ’å...\n",
      "\n",
      "--- æ­£åœ¨å¤„ç†é‚®æ”¿æŠ¥å‘Šçš„ æœ¬æœŸ æ•°æ® ---\n",
      "  âœ… æœ¬æœŸ æ•°æ®æå–å®Œæˆã€‚\n",
      "\n",
      "--- æ­£åœ¨å¤„ç†é‚®æ”¿æŠ¥å‘Šçš„ ä¸Šæœˆ æ•°æ® ---\n",
      "  âœ… ä¸Šæœˆ æ•°æ®æå–å®Œæˆã€‚\n",
      "\n",
      "--- æ­£åœ¨å¤„ç†é‚®æ”¿æŠ¥å‘Šçš„ å»å¹´åŒæœŸ æ•°æ® ---\n",
      "  âœ… å»å¹´åŒæœŸ æ•°æ®æå–å®Œæˆã€‚\n",
      "\n",
      "ğŸ‰ é‚®æ”¿æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: /Users/lava/Documents/å›½å®¶é‚®æ”¿å±€å‘å±•ç ”ç©¶ä¸­å¿ƒå®ä¹ /python_data_analysis/æŠ¥å‘Šæ•°æ®/è¾“å‡º/3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼/1_å…¨ç¨‹æ—¶é™72å°æ—¶å¦¥æŠ•ç‡åŠä¸­è½¬æ¬¡æ•°æ’å_202506.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3.1: é‚®æ”¿æŠ¥å‘Šæ‰€éœ€è¡¨æ ¼ç”Ÿæˆ è¡¨1 å…¨ç¨‹æ—¶é™ã€72å°æ—¶å¦¥æŠ•ç‡åŠä¸­è½¬æ¬¡æ•°æ’å\n",
    "# ==============================================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. è·¯å¾„å’Œå¸¸é‡å®šä¹‰ ---\n",
    "ROOT_PATH = Path.cwd()\n",
    "POSTAL_OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼\"\n",
    "POSTAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_file_paths(period_label):\n",
    "    \"\"\"è·å–æŒ‡å®šæ—¶æœŸçš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„\"\"\"\n",
    "    if period_label == \"æœ¬æœŸ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"data_analysis_result\",\n",
    "            \"turnover\": ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"temp\" / \"5_ä¸­è½¬æ•°æ®\",\n",
    "        }\n",
    "    elif period_label == \"ä¸Šæœˆ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{PREVIOUS_YEAR_MONTH}\"\n",
    "            / f\"data_analysis_result_{PREVIOUS_YEAR_MONTH}\",\n",
    "            \"turnover\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{PREVIOUS_YEAR_MONTH}\"\n",
    "            / f\"ä¸­è½¬æ•°æ®_{PREVIOUS_YEAR_MONTH}\",\n",
    "        }\n",
    "    elif period_label == \"å»å¹´åŒæœŸ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{LAST_YEAR_MONTH}\"\n",
    "            / f\"data_analysis_result_{LAST_YEAR_MONTH}\",\n",
    "            \"turnover\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{LAST_YEAR_MONTH}\"\n",
    "            / f\"ä¸­è½¬æ•°æ®_{LAST_YEAR_MONTH}\",\n",
    "        }\n",
    "    return {}\n",
    "\n",
    "\n",
    "# æ˜ç¡®å®šä¹‰å„ä¸ªå…¬å¸åˆ—è¡¨çš„ç”¨é€”\n",
    "COMPANIES_ALL = [\n",
    "    \"ä¸­é€š\",\n",
    "    \"åœ†é€š\",\n",
    "    \"æå…”\",\n",
    "    \"ç”³é€š\",\n",
    "    \"éŸµè¾¾\",\n",
    "    \"é¡ºä¸°\",\n",
    "    \"äº¬ä¸œ\",\n",
    "    \"EMS\",\n",
    "    \"å¾·é‚¦\",\n",
    "    \"å¿«åŒ…\",\n",
    "]\n",
    "# ç”¨äºè¡Œä¸šå¯¹æ¯”çš„å…¬å¸åˆ—è¡¨ï¼Œæ˜ç¡®æ’é™¤'å¿«åŒ…'\n",
    "COMPANIES_FOR_INDUSTRY_COMPARISON = [c for c in COMPANIES_ALL if c != \"å¿«åŒ…\"]\n",
    "COMPANY_FILE_MAP = {\n",
    "    \"EMS\": \"EMS\",\n",
    "    \"å¾·é‚¦\": \"å¾·é‚¦\",\n",
    "    \"æå…”\": \"æå…”\",\n",
    "    \"åœ†é€š\": \"åœ†é€š\",\n",
    "    \"é¡ºä¸°\": \"é¡ºä¸°\",\n",
    "    \"ä¸­é€š\": \"ä¸­é€š\",\n",
    "    \"äº¬ä¸œ\": \"äº¬ä¸œ\",\n",
    "    \"éŸµè¾¾\": \"éŸµè¾¾\",\n",
    "    \"ç”³é€š\": \"ç”³é€š\",\n",
    "    \"å¿«åŒ…\": \"é‚®æ”¿\",\n",
    "}\n",
    "POSTAL_METRICS_MAP = {\n",
    "    \"å…¨ç¨‹æ—¶é™ï¼ˆå°æ—¶ï¼‰\": \"å…¨ç¨‹æ—¶é™\",\n",
    "    \"72å°æ—¶å¦¥æŠ•ç‡\": \"72å°æ—¶å‡†æ—¶ç‡\",\n",
    "    \"48å°æ—¶å¦¥æŠ•ç‡\": \"48å°æ—¶å‡†æ—¶ç‡\",\n",
    "    \"ä¸­è½¬æ¬¡æ•°\": \"å¹³å‡ä¸­è½¬æ¬¡æ•°\",\n",
    "}\n",
    "HIGHER_IS_BETTER = [\"72å°æ—¶å¦¥æŠ•ç‡\", \"48å°æ—¶å¦¥æŠ•ç‡\"]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Part 1: æ•°æ®æå–å‡½æ•°\n",
    "# ==============================================================================\n",
    "def get_turnover_data(turnover_dir):\n",
    "    \"\"\"ä¸“é—¨ä»ä¸­è½¬æ•°æ®æ–‡ä»¶å¤¹æå–ä¸­è½¬æ¬¡æ•°\"\"\"\n",
    "    if not turnover_dir or not turnover_dir.exists():\n",
    "        print(f\"  - âš ï¸ è­¦å‘Šï¼šä¸­è½¬æ•°æ®ç›®å½•ä¸å­˜åœ¨: {turnover_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    turnover_results = {}\n",
    "    files = list(turnover_dir.glob(\"*.xlsx\"))\n",
    "    for company_key, file_prefix in COMPANY_FILE_MAP.items():\n",
    "        if company_key == \"å¿«åŒ…\":\n",
    "            company_file = next(\n",
    "                (f for f in files if \"å¿«åŒ…\" in f.name and \"å¼‚å¸¸\" not in f.name), None\n",
    "            )\n",
    "            if not company_file:\n",
    "                company_file = next(\n",
    "                    (f for f in files if \"é‚®æ”¿\" in f.name and \"å¼‚å¸¸\" not in f.name),\n",
    "                    None,\n",
    "                )\n",
    "        else:\n",
    "            company_file = next(\n",
    "                (f for f in files if file_prefix in f.name and \"å¼‚å¸¸\" not in f.name),\n",
    "                None,\n",
    "            )\n",
    "        if company_file:\n",
    "            try:\n",
    "                df = pd.read_excel(company_file)\n",
    "                if \"å¹³å‡ä¸­è½¬æ¬¡æ•°\" in df.columns:\n",
    "                    turnover_results[company_key] = df[\"å¹³å‡ä¸­è½¬æ¬¡æ•°\"].mean(skipna=True)\n",
    "            except Exception as e:\n",
    "                print(f\"  - âš ï¸ è­¦å‘Šï¼šè¯»å–ä¸­è½¬æ–‡ä»¶ {company_file.name} å¤±è´¥: {e}\")\n",
    "    if not turnover_results:\n",
    "        print(f\"  - âš ï¸ è­¦å‘Šï¼šåœ¨ {turnover_dir} ä¸­æœªèƒ½æå–åˆ°ä»»ä½•ä¸­è½¬æ•°æ®ã€‚\")\n",
    "        return pd.DataFrame()\n",
    "    df_turnover = pd.Series(turnover_results).to_frame(name=\"ä¸­è½¬æ¬¡æ•°\").T\n",
    "\n",
    "    # ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "    industry_competitors = [\n",
    "        c for c in df_turnover.columns if c in COMPANIES_FOR_INDUSTRY_COMPARISON\n",
    "    ]\n",
    "    if industry_competitors:\n",
    "        df_turnover[\"è¡Œä¸šå‡å€¼\"] = df_turnover[industry_competitors].mean(axis=1)\n",
    "        df_turnover[\"è¡Œä¸šæœ€ä¼˜\"] = df_turnover[industry_competitors].min(axis=1)\n",
    "    return df_turnover\n",
    "\n",
    "\n",
    "def get_postal_period_data(period_label):\n",
    "    \"\"\"ä¸ºé‚®æ”¿æŠ¥å‘Šæå–æ‰€æœ‰æ•°æ®ï¼Œæ•´åˆäº†ä¸¤ä¸ªæ•°æ®æº\"\"\"\n",
    "    print(f\"\\n--- æ­£åœ¨å¤„ç†é‚®æ”¿æŠ¥å‘Šçš„ {period_label} æ•°æ® ---\")\n",
    "    paths = get_file_paths(period_label)\n",
    "    input_dir, turnover_dir = paths.get(\"data_analysis\"), paths.get(\"turnover\")\n",
    "\n",
    "    df_main_metrics = pd.DataFrame()\n",
    "    if not input_dir or not input_dir.exists():\n",
    "        print(\n",
    "            f\"  - âš ï¸ è­¦å‘Šï¼š{period_label} çš„ data_analysis_result ç›®å½•æœªæ‰¾åˆ°: {input_dir}\"\n",
    "        )\n",
    "    else:\n",
    "        all_company_data = []\n",
    "        metrics_to_extract = {\n",
    "            k: v for k, v in POSTAL_METRICS_MAP.items() if k != \"ä¸­è½¬æ¬¡æ•°\"\n",
    "        }\n",
    "        for company_key, file_prefix in COMPANY_FILE_MAP.items():\n",
    "            file_path = input_dir / f\"{file_prefix}_data_analysis_result.xlsx\"\n",
    "            if not file_path.exists():\n",
    "                continue\n",
    "            try:\n",
    "                df_basic = pd.read_excel(file_path, sheet_name=\"åŸºç¡€æŒ‡æ ‡\").set_index(\n",
    "                    \"é¡¹ç›®\"\n",
    "                )\n",
    "                source_metrics = list(metrics_to_extract.values())\n",
    "                if all(item in df_basic.index for item in source_metrics):\n",
    "                    company_metrics = df_basic.loc[source_metrics, \"mean\"].rename(\n",
    "                        company_key\n",
    "                    )\n",
    "                    all_company_data.append(company_metrics)\n",
    "            except Exception as e:\n",
    "                print(f\"  - âš ï¸ è­¦å‘Šï¼šå¤„ç†æ–‡ä»¶ {file_path.name} å¤±è´¥: {e}\")\n",
    "        if all_company_data:\n",
    "            df_period = pd.concat(all_company_data, axis=1).T\n",
    "            df_period.rename(\n",
    "                columns=lambda x: [k for k, v in metrics_to_extract.items() if v == x][\n",
    "                    0\n",
    "                ],\n",
    "                inplace=True,\n",
    "            )\n",
    "            # (ä¿®æ”¹) ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "            industry_competitors = df_period.index.intersection(\n",
    "                COMPANIES_FOR_INDUSTRY_COMPARISON\n",
    "            ).tolist()\n",
    "            if industry_competitors:\n",
    "                df_period.loc[\"è¡Œä¸šå‡å€¼\"] = df_period.loc[industry_competitors].mean()\n",
    "                for metric in metrics_to_extract.keys():\n",
    "                    if metric in HIGHER_IS_BETTER:\n",
    "                        df_period.loc[\"è¡Œä¸šæœ€ä¼˜\", metric] = df_period.loc[\n",
    "                            industry_competitors, metric\n",
    "                        ].max()\n",
    "                    else:\n",
    "                        df_period.loc[\"è¡Œä¸šæœ€ä¼˜\", metric] = df_period.loc[\n",
    "                            industry_competitors, metric\n",
    "                        ].min()\n",
    "            df_main_metrics = df_period.T\n",
    "\n",
    "    df_turnover_metrics = get_turnover_data(turnover_dir)\n",
    "    df_final = pd.concat([df_main_metrics, df_turnover_metrics])\n",
    "    print(f\"  âœ… {period_label} æ•°æ®æå–å®Œæˆã€‚\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Part 2: æŠ¥å‘Šç”Ÿæˆå‡½æ•°\n",
    "# ==============================================================================\n",
    "def create_postal_report_table(df_current, df_mom, df_yoy):\n",
    "    report_cols = [\n",
    "        \"æŒ‡æ ‡\",\n",
    "        \"ç±»åˆ«\",\n",
    "        \"EMS\",\n",
    "        \"é‚®æ”¿\",\n",
    "        \"è¡Œä¸šå‡å€¼\",\n",
    "        \"è¡Œä¸šæœ€ä¼˜\",\n",
    "        \"EMSæ’å\",\n",
    "        \"é‚®æ”¿å¿«åŒ…æ’å\",\n",
    "    ]\n",
    "    source_value_cols = [\"EMS\", \"å¿«åŒ…\", \"è¡Œä¸šå‡å€¼\", \"è¡Œä¸šæœ€ä¼˜\"]\n",
    "    report_value_cols = [\"EMS\", \"é‚®æ”¿\", \"è¡Œä¸šå‡å€¼\", \"è¡Œä¸šæœ€ä¼˜\"]\n",
    "    # æ’åæ± å·²æ­£ç¡®ï¼Œæ— éœ€ä¿®æ”¹\n",
    "    ems_competitors = [c for c in COMPANIES_ALL if c != \"å¿«åŒ…\"]\n",
    "    postal_competitors = [c for c in COMPANIES_ALL if c != \"EMS\"]\n",
    "    if not df_mom.empty:\n",
    "        df_mom = df_mom.reindex(columns=df_current.columns)\n",
    "    if not df_yoy.empty:\n",
    "        df_yoy = df_yoy.reindex(columns=df_current.columns)\n",
    "    report_rows = [\n",
    "        f\"{metric}_{p}\"\n",
    "        for metric in POSTAL_METRICS_MAP\n",
    "        for p in [\"æœ¬æœŸ\", \"ç¯æ¯”\", \"åŒæ¯”\"]\n",
    "    ]\n",
    "    table_df = pd.DataFrame(index=report_rows, columns=report_cols).fillna(\"\")\n",
    "\n",
    "    for metric in POSTAL_METRICS_MAP.keys():\n",
    "        table_df.loc[f\"{metric}_æœ¬æœŸ\", \"æŒ‡æ ‡\"] = metric.replace(\"ï¼ˆå°æ—¶ï¼‰\", \"\")\n",
    "        table_df.loc[f\"{metric}_æœ¬æœŸ\", \"ç±»åˆ«\"] = CURRENT_MONTH_DISPLAY\n",
    "        table_df.loc[f\"{metric}_ç¯æ¯”\", \"ç±»åˆ«\"] = \"ç¯æ¯”\"\n",
    "        table_df.loc[f\"{metric}_åŒæ¯”\", \"ç±»åˆ«\"] = \"åŒæ¯”\"\n",
    "        if not df_current.empty and metric in df_current.index:\n",
    "            table_df.loc[f\"{metric}_æœ¬æœŸ\", report_value_cols] = df_current.loc[\n",
    "                metric, source_value_cols\n",
    "            ].values\n",
    "        if not df_mom.empty and metric in df_mom.index:\n",
    "            delta = (\n",
    "                df_current.loc[metric, source_value_cols]\n",
    "                - df_mom.loc[metric, source_value_cols]\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_ç¯æ¯”\", report_value_cols] = delta.round(4).values\n",
    "        if not df_yoy.empty and metric in df_yoy.index:\n",
    "            delta = (\n",
    "                df_current.loc[metric, source_value_cols]\n",
    "                - df_yoy.loc[metric, source_value_cols]\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_åŒæ¯”\", report_value_cols] = delta.round(4).values\n",
    "\n",
    "        ascending = metric not in HIGHER_IS_BETTER\n",
    "        if not df_current.empty and metric in df_current.index:\n",
    "            ranks = df_current.loc[metric, ems_competitors].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_æœ¬æœŸ\", \"EMSæ’å\"] = ranks.get(\"EMS\")\n",
    "            ranks = df_current.loc[metric, postal_competitors].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_æœ¬æœŸ\", \"é‚®æ”¿å¿«åŒ…æ’å\"] = ranks.get(\"å¿«åŒ…\")\n",
    "        if not df_mom.empty and metric in df_mom.index:\n",
    "            ranks = df_mom.loc[metric, ems_competitors].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_ç¯æ¯”\", \"EMSæ’å\"] = ranks.get(\"EMS\")\n",
    "            ranks = df_mom.loc[metric, postal_competitors].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_ç¯æ¯”\", \"é‚®æ”¿å¿«åŒ…æ’å\"] = ranks.get(\"å¿«åŒ…\")\n",
    "        if not df_yoy.empty and metric in df_yoy.index:\n",
    "            ranks = df_yoy.loc[metric, ems_competitors].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_åŒæ¯”\", \"EMSæ’å\"] = ranks.get(\"EMS\")\n",
    "            ranks = df_yoy.loc[metric, postal_competitors].rank(\n",
    "                method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "            )\n",
    "            table_df.loc[f\"{metric}_åŒæ¯”\", \"é‚®æ”¿å¿«åŒ…æ’å\"] = ranks.get(\"å¿«åŒ…\")\n",
    "\n",
    "    table_df.rename(columns={\"ç±»åˆ«\": \"æŒ‡æ ‡\", \"æŒ‡æ ‡\": \"ç±»åˆ«\"}, inplace=True)\n",
    "    return table_df[\n",
    "        [\"ç±»åˆ«\", \"æŒ‡æ ‡\"]\n",
    "        + [col for col in table_df.columns if col not in [\"ç±»åˆ«\", \"æŒ‡æ ‡\"]]\n",
    "    ]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Part 3 & æœ€ç»ˆæ‰§è¡Œå…¥å£\n",
    "# ==============================================================================\n",
    "def write_postal_formatted_excel(writer, df, sheet_name):\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    worksheet.set_column(\"A:H\", 15)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\n",
    "        f\"ğŸš€ å¼€å§‹ç”Ÿæˆ {CURRENT_YEAR_MONTH} æœˆåº¦é‚®æ”¿æŠ¥å‘Š è¡¨1ï¼šå…¨ç¨‹æ—¶é™ã€72å°æ—¶å¦¥æŠ•ç‡åŠä¸­è½¬æ¬¡æ•°æ’å...\"\n",
    "    )\n",
    "\n",
    "    df_current_postal = get_postal_period_data(\"æœ¬æœŸ\")\n",
    "    df_mom_postal = get_postal_period_data(\"ä¸Šæœˆ\")\n",
    "    df_yoy_postal = get_postal_period_data(\"å»å¹´åŒæœŸ\")\n",
    "\n",
    "    if df_current_postal.empty:\n",
    "        print(\"ğŸ›‘ æœ¬æœŸé‚®æ”¿æ•°æ®æœªèƒ½æˆåŠŸæå–ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚\")\n",
    "    else:\n",
    "        postal_table_df = create_postal_report_table(\n",
    "            df_current_postal, df_mom_postal, df_yoy_postal\n",
    "        )\n",
    "        output_path = (\n",
    "            POSTAL_OUTPUT_DIR\n",
    "            / f\"1_å…¨ç¨‹æ—¶é™72å°æ—¶å¦¥æŠ•ç‡åŠä¸­è½¬æ¬¡æ•°æ’å_{CURRENT_YEAR_MONTH}.xlsx\"\n",
    "        )\n",
    "        with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "            write_postal_formatted_excel(writer, postal_table_df, \"æ—¶é™åŠæ’å\")\n",
    "        print(f\"\\nğŸ‰ é‚®æ”¿æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116308ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹ç”Ÿæˆ è¡¨2 åˆ†å…¬é‡Œå¦¥æŠ•ç‡å’Œä¸­è½¬æ¬¡æ•°...\n",
      "\n",
      "--- æ­£åœ¨è®¡ç®— æœ¬æœŸ çš„æ‰€æœ‰åˆ†æ®µæŒ‡æ ‡ (æœ€ç»ˆç‰ˆ) ---\n",
      "  - æ­£åœ¨å¤„ç†: ä¸­é€š\n",
      "  - æ­£åœ¨å¤„ç†: åœ†é€š\n",
      "  - æ­£åœ¨å¤„ç†: æå…”\n",
      "  - æ­£åœ¨å¤„ç†: ç”³é€š\n",
      "  - æ­£åœ¨å¤„ç†: éŸµè¾¾\n",
      "  - æ­£åœ¨å¤„ç†: é¡ºä¸°\n",
      "  - æ­£åœ¨å¤„ç†: äº¬ä¸œ\n",
      "  - æ­£åœ¨å¤„ç†: EMS\n",
      "    -> [å®¡æŸ¥] EMS 600km+èˆªç©ºä»¶T+1å¦¥æŠ•ç‡: 10007 / 24993\n",
      "  - æ­£åœ¨å¤„ç†: å¾·é‚¦\n",
      "  - æ­£åœ¨å¤„ç†: å¿«åŒ…\n",
      "    -> [å®¡æŸ¥] å¿«åŒ… 600km+èˆªç©ºä»¶T+1å¦¥æŠ•ç‡: 111 / 1116\n",
      "\n",
      "--- æ­£åœ¨è®¡ç®— ä¸Šæœˆ çš„æ‰€æœ‰åˆ†æ®µæŒ‡æ ‡ (æœ€ç»ˆç‰ˆ) ---\n",
      "  - æ­£åœ¨å¤„ç†: ä¸­é€š\n",
      "  - æ­£åœ¨å¤„ç†: åœ†é€š\n",
      "  - æ­£åœ¨å¤„ç†: æå…”\n",
      "  - æ­£åœ¨å¤„ç†: ç”³é€š\n",
      "  - æ­£åœ¨å¤„ç†: éŸµè¾¾\n",
      "  - æ­£åœ¨å¤„ç†: é¡ºä¸°\n",
      "  - æ­£åœ¨å¤„ç†: äº¬ä¸œ\n",
      "  - æ­£åœ¨å¤„ç†: EMS\n",
      "    -> [å®¡æŸ¥] EMS 600km+èˆªç©ºä»¶T+1å¦¥æŠ•ç‡: 11996 / 15349\n",
      "  - æ­£åœ¨å¤„ç†: å¾·é‚¦\n",
      "  - æ­£åœ¨å¤„ç†: å¿«åŒ…\n",
      "    -> [å®¡æŸ¥] å¿«åŒ… 600km+èˆªç©ºä»¶T+1å¦¥æŠ•ç‡: 123 / 1028\n",
      "\n",
      "ğŸ‰ é‚®æ”¿æœˆæŠ¥ è¡¨2 åˆ†å…¬é‡Œå¦¥æŠ•ç‡å’Œä¸­è½¬æ¬¡æ•° å·²æˆåŠŸä¿å­˜è‡³: /Users/lava/Documents/å›½å®¶é‚®æ”¿å±€å‘å±•ç ”ç©¶ä¸­å¿ƒå®ä¹ /python_data_analysis/æŠ¥å‘Šæ•°æ®/è¾“å‡º/3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼/2_åˆ†å…¬é‡Œå¦¥æŠ•ç‡å’Œä¸­è½¬æ¬¡æ•°_202506.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3.2: é‚®æ”¿æŠ¥å‘Šæ‰€éœ€è¡¨æ ¼ç”Ÿæˆ è¡¨2 åˆ†å…¬é‡Œå¦¥æŠ•ç‡å’Œä¸­è½¬æ¬¡æ•°\n",
    "# ==============================================================================\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. å…¨å±€é…ç½® ---\n",
    "ROOT_PATH = Path.cwd()\n",
    "POSTAL_OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼\"\n",
    "POSTAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_file_paths(period_label):\n",
    "    base_dir = ROOT_PATH\n",
    "    month_str_map = {\"ä¸Šæœˆ\": PREVIOUS_YEAR_MONTH, \"å»å¹´åŒæœŸ\": LAST_YEAR_MONTH}\n",
    "    if period_label != \"æœ¬æœŸ\":\n",
    "        month_str = month_str_map.get(period_label, \"\")\n",
    "        base_dir = base_dir / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å…¥\" / \"historical_data\" / month_str\n",
    "        return {\n",
    "            \"data_analysis\": base_dir / f\"data_analysis_result_{month_str}\",\n",
    "            \"turnover\": base_dir / f\"ä¸­è½¬æ•°æ®_{month_str}\",\n",
    "        }\n",
    "    return {\n",
    "        \"data_analysis\": base_dir / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"data_analysis_result\",\n",
    "        \"turnover\": base_dir / \"æŠ¥å‘Šæ•°æ®\" / \"temp\" / \"5_ä¸­è½¬æ•°æ®\",\n",
    "    }\n",
    "\n",
    "\n",
    "# æ˜ç¡®å®šä¹‰å„ä¸ªå…¬å¸åˆ—è¡¨çš„ç”¨é€”\n",
    "COMPANIES_ALL = [\n",
    "    \"ä¸­é€š\",\n",
    "    \"åœ†é€š\",\n",
    "    \"æå…”\",\n",
    "    \"ç”³é€š\",\n",
    "    \"éŸµè¾¾\",\n",
    "    \"é¡ºä¸°\",\n",
    "    \"äº¬ä¸œ\",\n",
    "    \"EMS\",\n",
    "    \"å¾·é‚¦\",\n",
    "    \"å¿«åŒ…\",\n",
    "]\n",
    "# ç”¨äºè¡Œä¸šå¯¹æ¯”çš„å…¬å¸åˆ—è¡¨ï¼Œæ˜ç¡®æ’é™¤'å¿«åŒ…'\n",
    "COMPANIES_FOR_INDUSTRY_COMPARISON = [c for c in COMPANIES_ALL if c != \"å¿«åŒ…\"]\n",
    "COMPANY_FILE_MAP = {\"EMS\": \"EMS\", \"å¿«åŒ…\": \"é‚®æ”¿\"}\n",
    "\n",
    "\n",
    "# --- 2. æ ¸å¿ƒè®¡ç®—å‡½æ•° ---\n",
    "def calculate_all_segmented_metrics_optimized(period_label):\n",
    "    print(f\"\\n--- æ­£åœ¨è®¡ç®— {period_label} çš„æ‰€æœ‰åˆ†æ®µæŒ‡æ ‡ (æœ€ç»ˆç‰ˆ) ---\")\n",
    "    paths = get_file_paths(period_label)\n",
    "    data_analysis_dir, turnover_dir = paths.get(\"data_analysis\"), paths.get(\"turnover\")\n",
    "\n",
    "    if not data_analysis_dir or not data_analysis_dir.exists():\n",
    "        print(f\"  - âŒ é”™è¯¯ï¼šæ•°æ®æºç›®å½•ä¸å­˜åœ¨: {data_analysis_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_company_results = {}\n",
    "\n",
    "    for company_key in COMPANIES_ALL:\n",
    "        file_prefix = COMPANY_FILE_MAP.get(company_key, company_key)\n",
    "        detail_file = data_analysis_dir / f\"{file_prefix}_data_analysis_result.xlsx\"\n",
    "\n",
    "        if not detail_file.exists():\n",
    "            continue\n",
    "\n",
    "        print(f\"  - æ­£åœ¨å¤„ç†: {company_key}\")\n",
    "        try:\n",
    "            df_detail = pd.read_excel(detail_file, sheet_name=\"çº¿è·¯è¯¦ç»†æ•°æ®\")\n",
    "            df_summary = pd.read_excel(detail_file, sheet_name=\"çº¿è·¯æ±‡æ€»æ•°æ®\")\n",
    "            if df_detail.empty or df_summary.empty:\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"    -> è­¦å‘Š: è¯»å–æ–‡ä»¶ {detail_file.name} å¤±è´¥: {e}\")\n",
    "            continue\n",
    "\n",
    "        if \"å¯„å‡ºåŸå¸‚\" in df_detail.columns and \"å¯„è¾¾åŸå¸‚\" in df_detail.columns:\n",
    "            df_detail[\"è·¯çº¿\"] = (\n",
    "                df_detail[\"å¯„å‡ºåŸå¸‚\"].astype(str)\n",
    "                + \"-\"\n",
    "                + df_detail[\"å¯„è¾¾åŸå¸‚\"].astype(str)\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"    -> è­¦å‘Š: {detail_file.name} (è¯¦ç»†æ•°æ®) ç¼ºå°‘'å¯„å‡ºåŸå¸‚'æˆ–'å¯„è¾¾åŸå¸‚'ã€‚\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        if \"è·¯çº¿\" in df_summary.columns and \"å¿«é€’æ•°é‡\" in df_summary.columns:\n",
    "            df = pd.merge(\n",
    "                df_detail, df_summary[[\"è·¯çº¿\", \"å¿«é€’æ•°é‡\"]], on=\"è·¯çº¿\", how=\"left\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"    -> è­¦å‘Š: {detail_file.name} (æ±‡æ€»æ•°æ®) ç¼ºå°‘'è·¯çº¿'æˆ–'å¿«é€’æ•°é‡'ï¼Œå°†ä½¿ç”¨ç®—æœ¯å¹³å‡ã€‚\"\n",
    "            )\n",
    "            df = df_detail.copy()\n",
    "            df[\"å¿«é€’æ•°é‡\"] = 1\n",
    "\n",
    "        turnover_file = (\n",
    "            next(turnover_dir.glob(f\"{file_prefix}*.xlsx\"), None)\n",
    "            if turnover_dir and turnover_dir.exists()\n",
    "            else None\n",
    "        )\n",
    "        if turnover_file:\n",
    "            try:\n",
    "                df_turnover = pd.read_excel(turnover_file)\n",
    "                if (\n",
    "                    \"å‡ºå‘åŸå¸‚\" in df_turnover.columns\n",
    "                    and \"åˆ°è¾¾åŸå¸‚\" in df_turnover.columns\n",
    "                    and \"å¹³å‡ä¸­è½¬æ¬¡æ•°\" in df_turnover.columns\n",
    "                ):\n",
    "                    df_turnover[\"è·¯çº¿\"] = (\n",
    "                        df_turnover[\"å‡ºå‘åŸå¸‚\"].astype(str)\n",
    "                        + \"-\"\n",
    "                        + df_turnover[\"åˆ°è¾¾åŸå¸‚\"].astype(str)\n",
    "                    )\n",
    "                    df_turnover_agg = (\n",
    "                        df_turnover.groupby(\"è·¯çº¿\")[[\"å¹³å‡ä¸­è½¬æ¬¡æ•°\"]]\n",
    "                        .mean()\n",
    "                        .reset_index()\n",
    "                    )\n",
    "                    df = pd.merge(df, df_turnover_agg, on=\"è·¯çº¿\", how=\"left\")\n",
    "            except Exception as e:\n",
    "                print(f\"    -> è­¦å‘Š: å¤„ç†ä¸­è½¬æ–‡ä»¶ {turnover_file.name} æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "\n",
    "        required_cols = [\"å…¬é‡Œ\", \"T+1_achieved\", \"T+2_achieved\", \"is_air\"]\n",
    "        if not all(c in df.columns for c in required_cols):\n",
    "            print(f\"    -> è­¦å‘Š: æ–‡ä»¶ {detail_file.name} ç¼ºå°‘å¿…è¦çš„é¢„è®¡ç®—åˆ—ï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        df_under_600, df_over_600 = df[df[\"å…¬é‡Œ\"] <= 600], df[df[\"å…¬é‡Œ\"] > 600]\n",
    "        df_over_600_air = df_over_600[df_over_600[\"is_air\"] == True]\n",
    "\n",
    "        if company_key in [\"EMS\", \"å¿«åŒ…\"]:\n",
    "            denominator = len(df_over_600_air)\n",
    "            numerator = (\n",
    "                df_over_600_air[\"T+1_achieved\"].sum()\n",
    "                if \"T+1_achieved\" in df_over_600_air\n",
    "                else 0\n",
    "            )\n",
    "            print(\n",
    "                f\"    -> [å®¡æŸ¥] {company_key} 600km+èˆªç©ºä»¶T+1å¦¥æŠ•ç‡: {numerator} / {denominator}\"\n",
    "            )\n",
    "\n",
    "        def weighted_avg_turnover(df_segment):\n",
    "            if (\n",
    "                df_segment.empty\n",
    "                or \"å¹³å‡ä¸­è½¬æ¬¡æ•°\" not in df_segment.columns\n",
    "                or \"å¿«é€’æ•°é‡\" not in df_segment.columns\n",
    "                or df_segment[\"å¹³å‡ä¸­è½¬æ¬¡æ•°\"].isna().all()\n",
    "            ):\n",
    "                return np.nan\n",
    "            valid_segment = df_segment.dropna(subset=[\"å¹³å‡ä¸­è½¬æ¬¡æ•°\", \"å¿«é€’æ•°é‡\"])\n",
    "            if valid_segment.empty or valid_segment[\"å¿«é€’æ•°é‡\"].sum() == 0:\n",
    "                return np.nan\n",
    "            return np.average(\n",
    "                valid_segment[\"å¹³å‡ä¸­è½¬æ¬¡æ•°\"], weights=valid_segment[\"å¿«é€’æ•°é‡\"]\n",
    "            )\n",
    "\n",
    "        all_company_results[company_key] = {\n",
    "            \"600å…¬é‡Œä»¥ä¸‹ T+1å¦¥æŠ•ç‡\": df_under_600[\"T+1_achieved\"].mean(),\n",
    "            \"600å…¬é‡Œä»¥ä¸‹ ä¸­è½¬æ¬¡æ•°\": weighted_avg_turnover(df_under_600),\n",
    "            \"600å…¬é‡Œä»¥ä¸Š å…¨äº§å“T+1å¦¥æŠ•ç‡\": df_over_600[\"T+1_achieved\"].mean(),\n",
    "            \"600å…¬é‡Œä»¥ä¸Š å…¨äº§å“T+2å¦¥æŠ•ç‡\": df_over_600[\"T+2_achieved\"].mean(),\n",
    "            \"600å…¬é‡Œä»¥ä¸Š å…¨äº§å“ä¸­è½¬æ¬¡æ•°\": weighted_avg_turnover(df_over_600),\n",
    "            \"600å…¬é‡Œä»¥ä¸Š èˆªç©ºä»¶T+1å¦¥æŠ•ç‡\": df_over_600_air[\"T+1_achieved\"].mean()\n",
    "            if not df_over_600_air.empty\n",
    "            else np.nan,\n",
    "        }\n",
    "\n",
    "    if not all_company_results:\n",
    "        return pd.DataFrame()\n",
    "    df_results = pd.DataFrame.from_dict(all_company_results, orient=\"index\")\n",
    "\n",
    "    industry_metrics = list(df_results.columns)\n",
    "    # (ä¿®æ”¹) ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "    industry_competitors = df_results.index.intersection(\n",
    "        COMPANIES_FOR_INDUSTRY_COMPARISON\n",
    "    ).tolist()\n",
    "    if industry_competitors:\n",
    "        df_results.loc[\"è¡Œä¸šå‡å€¼\"] = df_results.loc[\n",
    "            industry_competitors, industry_metrics\n",
    "        ].mean()\n",
    "        for metric in industry_metrics:\n",
    "            if \"å¦¥æŠ•ç‡\" in metric:\n",
    "                df_results.loc[\"è¡Œä¸šæœ€ä¼˜\", metric] = df_results.loc[\n",
    "                    industry_competitors, metric\n",
    "                ].max()\n",
    "            else:\n",
    "                df_results.loc[\"è¡Œä¸šæœ€ä¼˜\", metric] = df_results.loc[\n",
    "                    industry_competitors, metric\n",
    "                ].min()\n",
    "\n",
    "    return df_results.loc[\n",
    "        df_results.index.intersection([\"EMS\", \"å¿«åŒ…\", \"è¡Œä¸šå‡å€¼\", \"è¡Œä¸šæœ€ä¼˜\"])\n",
    "    ].T\n",
    "\n",
    "\n",
    "def format_to_report_style(df_period):\n",
    "    if df_period.empty:\n",
    "        return pd.DataFrame()\n",
    "    df_final = (\n",
    "        df_period.rename(columns={\"å¿«åŒ…\": \"é‚®æ”¿å¿«åŒ…\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"æŒ‡æ ‡\"})\n",
    "    )\n",
    "    split_data = df_final[\"æŒ‡æ ‡\"].str.split(\" \", n=1, expand=True)\n",
    "    df_final.insert(0, \"ç±»åˆ«\", split_data[0])\n",
    "    df_final[\"æŒ‡æ ‡\"] = split_data[1]\n",
    "    return df_final[[\"ç±»åˆ«\", \"æŒ‡æ ‡\", \"EMS\", \"é‚®æ”¿å¿«åŒ…\", \"è¡Œä¸šå‡å€¼\", \"è¡Œä¸šæœ€ä¼˜\"]]\n",
    "\n",
    "\n",
    "# --- 3. ä¸»æ‰§è¡Œå…¥å£ ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ å¼€å§‹ç”Ÿæˆ è¡¨2 åˆ†å…¬é‡Œå¦¥æŠ•ç‡å’Œä¸­è½¬æ¬¡æ•°...\")\n",
    "    df_current = calculate_all_segmented_metrics_optimized(\"æœ¬æœŸ\")\n",
    "    df_mom = calculate_all_segmented_metrics_optimized(\"ä¸Šæœˆ\")\n",
    "    table_current = format_to_report_style(df_current)\n",
    "    table_mom = format_to_report_style(df_mom)\n",
    "    output_path = (\n",
    "        POSTAL_OUTPUT_DIR / f\"2_åˆ†å…¬é‡Œå¦¥æŠ•ç‡å’Œä¸­è½¬æ¬¡æ•°_{CURRENT_YEAR_MONTH}.xlsx\"\n",
    "    )\n",
    "    with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "        if not table_current.empty:\n",
    "            table_current.to_excel(writer, sheet_name=\"æœ¬æœŸ\", index=False)\n",
    "        if not table_mom.empty:\n",
    "            table_mom.to_excel(writer, sheet_name=\"ç¯æ¯”\", index=False)\n",
    "        workbook = writer.book\n",
    "        percent_format, float_format = (\n",
    "            workbook.add_format({\"num_format\": \"0.00%\"}),\n",
    "            workbook.add_format({\"num_format\": \"0.00\"}),\n",
    "        )\n",
    "        for sheet_name in writer.sheets:\n",
    "            worksheet, df_to_format = (\n",
    "                writer.sheets[sheet_name],\n",
    "                table_current if sheet_name == \"æœ¬æœŸ\" else table_mom,\n",
    "            )\n",
    "            if df_to_format.empty:\n",
    "                continue\n",
    "            for r in range(len(df_to_format)):\n",
    "                cell_format = (\n",
    "                    percent_format\n",
    "                    if \"å¦¥æŠ•ç‡\" in str(df_to_format.iat[r, 1])\n",
    "                    else float_format\n",
    "                )\n",
    "                for c in range(2, 6):\n",
    "                    if pd.notna(df_to_format.iat[r, c]):\n",
    "                        worksheet.write_number(\n",
    "                            r + 1, c, df_to_format.iat[r, c], cell_format\n",
    "                        )\n",
    "            worksheet.set_column(\"A:B\", 25)\n",
    "            worksheet.set_column(\"C:F\", 15)\n",
    "    print(f\"\\nğŸ‰ é‚®æ”¿æœˆæŠ¥ è¡¨2 åˆ†å…¬é‡Œå¦¥æŠ•ç‡å’Œä¸­è½¬æ¬¡æ•° å·²æˆåŠŸä¿å­˜è‡³: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c043c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹ç”Ÿæˆ è¡¨3 åˆ†ç¯èŠ‚æ—¶é™åŠæ’å...\n",
      "  - æ­£åœ¨è¯»å–å½“æœˆã€ç¯æ¯”å’ŒåŒæ¯”çš„æºæ•°æ®...\n",
      "  - [Sheet 1/3] æ­£åœ¨ç”Ÿæˆ 'åˆ†ç¯èŠ‚æ—¶é™åˆ†æ'...\n",
      "  - [Sheet 2/3] æ­£åœ¨ç”Ÿæˆ 'EMSåŒç¯æ¯”'...\n",
      "  - æ­£åœ¨ä¸º 'EMS' ç”ŸæˆåŸå¸‚ç»´åº¦æ•°æ®...\n",
      "  - [Sheet 3/3] æ­£åœ¨ç”Ÿæˆ 'é‚®æ”¿å¿«åŒ…åŒç¯æ¯”'...\n",
      "  - æ­£åœ¨ä¸º 'å¿«åŒ…' ç”ŸæˆåŸå¸‚ç»´åº¦æ•°æ®...\n",
      "  - æ­£åœ¨æ ¼å¼åŒ–è¡¨æ ¼å¹¶ä¿å­˜è‡³åŒä¸€ä¸ªExcelæ–‡ä»¶...\n",
      "\n",
      "ğŸ‰ æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: /Users/lava/Documents/å›½å®¶é‚®æ”¿å±€å‘å±•ç ”ç©¶ä¸­å¿ƒå®ä¹ /python_data_analysis/æŠ¥å‘Šæ•°æ®/è¾“å‡º/3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼/3_åˆ†ç¯èŠ‚æ—¶é™åŠæ’å_202506.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3.3: é‚®æ”¿æŠ¥å‘Šæ‰€éœ€è¡¨æ ¼ç”Ÿæˆ - è¡¨3\n",
    "# ==============================================================================\n",
    "# ç¡®ä¿åœ¨è„šæœ¬å¼€å¤´æœ‰å¿…è¦çš„å¯¼å…¥\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment, Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# --- 1. å…¨å±€é…ç½® ---\n",
    "try:\n",
    "    ROOT_PATH = Path.cwd()\n",
    "    POSTAL_OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼\"\n",
    "    POSTAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "except NameError:\n",
    "    ROOT_PATH = Path(\".\")\n",
    "    POSTAL_OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼\"\n",
    "    POSTAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_file_paths(period_label):\n",
    "    if period_label == \"æœ¬æœŸ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"data_analysis_result\"\n",
    "        }\n",
    "    elif period_label == \"ä¸Šæœˆ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{PREVIOUS_YEAR_MONTH}\"\n",
    "            / f\"data_analysis_result_{PREVIOUS_YEAR_MONTH}\"\n",
    "        }\n",
    "    elif period_label == \"å»å¹´åŒæœŸ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{LAST_YEAR_MONTH}\"\n",
    "            / f\"data_analysis_result_{LAST_YEAR_MONTH}\"\n",
    "        }\n",
    "    return {}\n",
    "\n",
    "\n",
    "COMPANY_FILE_MAP = {\n",
    "    \"EMS\": \"EMS\",\n",
    "    \"å¿«åŒ…\": \"é‚®æ”¿\",\n",
    "    \"ä¸­é€š\": \"ä¸­é€š\",\n",
    "    \"åœ†é€š\": \"åœ†é€š\",\n",
    "    \"æå…”\": \"æå…”\",\n",
    "    \"ç”³é€š\": \"ç”³é€š\",\n",
    "    \"éŸµè¾¾\": \"éŸµè¾¾\",\n",
    "    \"é¡ºä¸°\": \"é¡ºä¸°\",\n",
    "    \"äº¬ä¸œ\": \"äº¬ä¸œ\",\n",
    "    \"å¾·é‚¦\": \"å¾·é‚¦\",\n",
    "}\n",
    "# ç”¨äºè¡Œä¸šå¯¹æ¯”çš„å…¬å¸åˆ—è¡¨ï¼Œæ˜ç¡®æ’é™¤'å¿«åŒ…'\n",
    "COMPANIES_FOR_INDUSTRY_COMPARISON = [c for c in COMPANY_FILE_MAP.keys() if c != \"å¿«åŒ…\"]\n",
    "\n",
    "METRICS_OF_INTEREST = [\"å¯„å‡ºåœ°å¤„ç†æ—¶é™\", \"è¿è¾“æ—¶é™\", \"å¯„è¾¾åœ°å¤„ç†æ—¶é™\", \"æŠ•é€’æ—¶é™\"]\n",
    "CITY_SHEET_METRICS = [\"å¯„å‡ºåœ°å¤„ç†æ—¶é™\", \"å¯„è¾¾åœ°å¤„ç†æ—¶é™\", \"æŠ•é€’æ—¶é™\"]\n",
    "COMPANY_COL, RANK_SUFFIX, SHEET_NAME = \"ä¼ä¸šåç§°\", \"-æ’å\", \"çº¿è·¯è¯¦ç»†æ•°æ®\"\n",
    "\n",
    "\n",
    "# --- 2. è¾…åŠ©å‡½æ•° ---\n",
    "def read_data_from_folder(folder_path, sheet_name=SHEET_NAME, company_col=COMPANY_COL):\n",
    "    if not folder_path or not folder_path.is_dir():\n",
    "        return pd.DataFrame()\n",
    "    files_to_read = list(folder_path.glob(\"*.xlsx\"))\n",
    "    if not files_to_read:\n",
    "        return pd.DataFrame()\n",
    "    df_list = []\n",
    "    for f_path in files_to_read:\n",
    "        company_name_standard = next(\n",
    "            (\n",
    "                std_name\n",
    "                for std_name, prefix in COMPANY_FILE_MAP.items()\n",
    "                if prefix in f_path.name\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if not company_name_standard:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_excel(\n",
    "                f_path,\n",
    "                sheet_name=sheet_name,\n",
    "                usecols=[\"å¯„å‡ºåŸå¸‚\", \"å¯„è¾¾åŸå¸‚\"] + METRICS_OF_INTEREST,\n",
    "            )\n",
    "            df[company_col] = company_name_standard\n",
    "            df_list.append(df)\n",
    "        except Exception:\n",
    "            continue\n",
    "    if not df_list:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "def calculate_special_ranks(df):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    for metric in METRICS_OF_INTEREST:\n",
    "        rank_col = f\"{metric}{RANK_SUFFIX}\"\n",
    "        df[rank_col] = np.nan\n",
    "        if \"EMS\" in df.index:\n",
    "            df_for_ems = df.drop(index=\"å¿«åŒ…\", errors=\"ignore\")\n",
    "            df.loc[\"EMS\", rank_col] = (\n",
    "                df_for_ems[metric].rank(method=\"min\", ascending=True).get(\"EMS\")\n",
    "            )\n",
    "        if \"å¿«åŒ…\" in df.index:\n",
    "            df_for_kuai = df.drop(index=\"EMS\", errors=\"ignore\")\n",
    "            df.loc[\"å¿«åŒ…\", rank_col] = (\n",
    "                df_for_kuai[metric].rank(method=\"min\", ascending=True).get(\"å¿«åŒ…\")\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 3. ç”ŸæˆåŸå¸‚ç»´åº¦å¯¹æ¯”è¡¨çš„å‡½æ•° ---\n",
    "def create_city_comparison_sheet(\n",
    "    company_name: str, df_current_raw, df_mom_raw, df_yoy_raw\n",
    "):\n",
    "    print(f\"  - æ­£åœ¨ä¸º '{company_name}' ç”ŸæˆåŸå¸‚ç»´åº¦æ•°æ®...\")\n",
    "    origin_metric, dest_metrics = [\"å¯„å‡ºåœ°å¤„ç†æ—¶é™\"], [\"å¯„è¾¾åœ°å¤„ç†æ—¶é™\", \"æŠ•é€’æ—¶é™\"]\n",
    "\n",
    "    def get_period_data(df_raw, company):\n",
    "        if df_raw.empty:\n",
    "            return pd.DataFrame()\n",
    "        df_company = df_raw[df_raw[COMPANY_COL] == company].copy()\n",
    "        if df_company.empty:\n",
    "            return pd.DataFrame()\n",
    "        df_origin = df_company.groupby(\"å¯„å‡ºåŸå¸‚\")[origin_metric].mean()\n",
    "        df_dest = df_company.groupby(\"å¯„è¾¾åŸå¸‚\")[dest_metrics].mean()\n",
    "        df_merged = pd.merge(\n",
    "            df_origin, df_dest, left_index=True, right_index=True, how=\"outer\"\n",
    "        )\n",
    "        df_merged.index.name = \"åŸå¸‚\"\n",
    "        return df_merged\n",
    "\n",
    "    df_current_city = get_period_data(df_current_raw, company_name)\n",
    "    df_mom_city = get_period_data(df_mom_raw, company_name)\n",
    "    df_yoy_city = get_period_data(df_yoy_raw, company_name)\n",
    "\n",
    "    df_current_city = df_current_city.add_suffix(f\"_{CURRENT_YEAR_MONTH}\")\n",
    "    df_mom_city = df_mom_city.add_suffix(f\"_{PREVIOUS_YEAR_MONTH}\")\n",
    "    df_yoy_city = df_yoy_city.add_suffix(f\"_{LAST_YEAR_MONTH}\")\n",
    "\n",
    "    df_merged_all_periods = pd.concat(\n",
    "        [df_current_city, df_mom_city, df_yoy_city], axis=1\n",
    "    )\n",
    "    final_cols_ordered = []\n",
    "\n",
    "    for metric in CITY_SHEET_METRICS:\n",
    "        current_col, mom_col, yoy_col = (\n",
    "            f\"{metric}_{CURRENT_YEAR_MONTH}\",\n",
    "            f\"{metric}_{PREVIOUS_YEAR_MONTH}\",\n",
    "            f\"{metric}_{LAST_YEAR_MONTH}\",\n",
    "        )\n",
    "        df_merged_all_periods[f\"{metric}_ç¯æ¯”å»¶é•¿\"] = df_merged_all_periods.get(\n",
    "            current_col\n",
    "        ) - df_merged_all_periods.get(mom_col)\n",
    "        df_merged_all_periods[f\"{metric}_åŒæ¯”å»¶é•¿\"] = df_merged_all_periods.get(\n",
    "            current_col\n",
    "        ) - df_merged_all_periods.get(yoy_col)\n",
    "        df_merged_all_periods[f\"{metric}_ç¯æ¯”å»¶é•¿å¹…åº¦\"] = np.where(\n",
    "            df_merged_all_periods[mom_col].notna()\n",
    "            & (df_merged_all_periods[mom_col] != 0),\n",
    "            df_merged_all_periods[f\"{metric}_ç¯æ¯”å»¶é•¿\"]\n",
    "            / df_merged_all_periods[mom_col],\n",
    "            np.nan,\n",
    "        )\n",
    "        df_merged_all_periods[f\"{metric}_åŒæ¯”å»¶é•¿å¹…åº¦\"] = np.where(\n",
    "            df_merged_all_periods[yoy_col].notna()\n",
    "            & (df_merged_all_periods[yoy_col] != 0),\n",
    "            df_merged_all_periods[f\"{metric}_åŒæ¯”å»¶é•¿\"]\n",
    "            / df_merged_all_periods[yoy_col],\n",
    "            np.nan,\n",
    "        )\n",
    "        final_cols_ordered.extend(\n",
    "            [\n",
    "                current_col,\n",
    "                mom_col,\n",
    "                yoy_col,\n",
    "                f\"{metric}_ç¯æ¯”å»¶é•¿\",\n",
    "                f\"{metric}_ç¯æ¯”å»¶é•¿å¹…åº¦\",\n",
    "                f\"{metric}_åŒæ¯”å»¶é•¿\",\n",
    "                f\"{metric}_åŒæ¯”å»¶é•¿å¹…åº¦\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    df_final = df_merged_all_periods.reindex(columns=final_cols_ordered).copy()\n",
    "    return df_final.reset_index()\n",
    "\n",
    "\n",
    "# --- 4. æ ¸å¿ƒæ‰§è¡Œå‡½æ•° ---\n",
    "def generate_segment_times_table():\n",
    "    print(\"ğŸš€ å¼€å§‹ç”Ÿæˆ è¡¨3 åˆ†ç¯èŠ‚æ—¶é™åŠæ’å...\")\n",
    "    print(\"  - æ­£åœ¨è¯»å–å½“æœˆã€ç¯æ¯”å’ŒåŒæ¯”çš„æºæ•°æ®...\")\n",
    "    df_current_raw = read_data_from_folder(get_file_paths(\"æœ¬æœŸ\").get(\"data_analysis\"))\n",
    "    df_mom_raw = read_data_from_folder(get_file_paths(\"ä¸Šæœˆ\").get(\"data_analysis\"))\n",
    "    df_yoy_raw = read_data_from_folder(get_file_paths(\"å»å¹´åŒæœŸ\").get(\"data_analysis\"))\n",
    "    if df_current_raw.empty:\n",
    "        print(f\"  - âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°å½“æœˆæ•°æ®ï¼Œæ— æ³•ç”Ÿæˆè¡¨æ ¼ã€‚\")\n",
    "        return\n",
    "\n",
    "    print(\"  - [Sheet 1/3] æ­£åœ¨ç”Ÿæˆ 'åˆ†ç¯èŠ‚æ—¶é™åˆ†æ'...\")\n",
    "\n",
    "    def aggregate_by_company(df_raw):\n",
    "        return (\n",
    "            df_raw.groupby(COMPANY_COL)[METRICS_OF_INTEREST].mean()\n",
    "            if not df_raw.empty\n",
    "            else pd.DataFrame()\n",
    "        )\n",
    "\n",
    "    df_current, df_mom_source, df_yoy_source = (\n",
    "        aggregate_by_company(df_current_raw),\n",
    "        aggregate_by_company(df_mom_raw),\n",
    "        aggregate_by_company(df_yoy_raw),\n",
    "    )\n",
    "    df_current, df_mom_source, df_yoy_source = (\n",
    "        calculate_special_ranks(df_current),\n",
    "        calculate_special_ranks(df_mom_source),\n",
    "        calculate_special_ranks(df_yoy_source),\n",
    "    )\n",
    "\n",
    "    # ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "    df_current_industry = df_current.loc[\n",
    "        df_current.index.intersection(COMPANIES_FOR_INDUSTRY_COMPARISON)\n",
    "    ]\n",
    "    industry_mean_current = df_current_industry[METRICS_OF_INTEREST].mean()\n",
    "    industry_best_current = df_current_industry[METRICS_OF_INTEREST].min()\n",
    "    if not df_mom_source.empty:\n",
    "        df_mom_industry = df_mom_source.loc[\n",
    "            df_mom_source.index.intersection(COMPANIES_FOR_INDUSTRY_COMPARISON)\n",
    "        ]\n",
    "        industry_mean_mom, industry_best_mom = (\n",
    "            df_mom_industry[METRICS_OF_INTEREST].mean(),\n",
    "            df_mom_industry[METRICS_OF_INTEREST].min(),\n",
    "        )\n",
    "    else:\n",
    "        industry_mean_mom, industry_best_mom = (\n",
    "            pd.Series(dtype=float),\n",
    "            pd.Series(dtype=float),\n",
    "        )\n",
    "    if not df_yoy_source.empty:\n",
    "        df_yoy_industry = df_yoy_source.loc[\n",
    "            df_yoy_source.index.intersection(COMPANIES_FOR_INDUSTRY_COMPARISON)\n",
    "        ]\n",
    "        industry_mean_yoy, industry_best_yoy = (\n",
    "            df_yoy_industry[METRICS_OF_INTEREST].mean(),\n",
    "            df_yoy_industry[METRICS_OF_INTEREST].min(),\n",
    "        )\n",
    "    else:\n",
    "        industry_mean_yoy, industry_best_yoy = (\n",
    "            pd.Series(dtype=float),\n",
    "            pd.Series(dtype=float),\n",
    "        )\n",
    "\n",
    "    index_tuples = [\n",
    "        (metric, p)\n",
    "        for metric in METRICS_OF_INTEREST\n",
    "        for p in [CURRENT_MONTH_DISPLAY, \"ç¯æ¯”\", \"åŒæ¯”\"]\n",
    "    ]\n",
    "    multi_index = pd.MultiIndex.from_tuples(index_tuples, names=[\"æŒ‡æ ‡\", \"\"])\n",
    "    result_columns = [\n",
    "        \"EMS\",\n",
    "        \"é‚®æ”¿å¿«åŒ…\",\n",
    "        \"è¡Œä¸šå‡å€¼\",\n",
    "        \"è¡Œä¸šæœ€ä¼˜\",\n",
    "        \"EMSæ’å\",\n",
    "        \"é‚®æ”¿å¿«åŒ…æ’å\",\n",
    "    ]\n",
    "    df_sheet1 = pd.DataFrame(index=multi_index, columns=result_columns).sort_index()\n",
    "\n",
    "    for metric in METRICS_OF_INTEREST:\n",
    "        rank_col = f\"{metric}{RANK_SUFFIX}\"\n",
    "        df_sheet1.loc[(metric, CURRENT_MONTH_DISPLAY), \"EMS\"] = (\n",
    "            df_current.loc[\"EMS\", metric] if \"EMS\" in df_current.index else np.nan\n",
    "        )\n",
    "        df_sheet1.loc[(metric, CURRENT_MONTH_DISPLAY), \"é‚®æ”¿å¿«åŒ…\"] = (\n",
    "            df_current.loc[\"å¿«åŒ…\", metric] if \"å¿«åŒ…\" in df_current.index else np.nan\n",
    "        )\n",
    "        df_sheet1.loc[(metric, CURRENT_MONTH_DISPLAY), \"è¡Œä¸šå‡å€¼\"] = (\n",
    "            industry_mean_current.get(metric)\n",
    "        )\n",
    "        df_sheet1.loc[(metric, CURRENT_MONTH_DISPLAY), \"è¡Œä¸šæœ€ä¼˜\"] = (\n",
    "            industry_best_current.get(metric)\n",
    "        )\n",
    "        df_sheet1.loc[(metric, CURRENT_MONTH_DISPLAY), \"EMSæ’å\"] = (\n",
    "            df_current.loc[\"EMS\", rank_col] if \"EMS\" in df_current.index else np.nan\n",
    "        )\n",
    "        df_sheet1.loc[(metric, CURRENT_MONTH_DISPLAY), \"é‚®æ”¿å¿«åŒ…æ’å\"] = (\n",
    "            df_current.loc[\"å¿«åŒ…\", rank_col] if \"å¿«åŒ…\" in df_current.index else np.nan\n",
    "        )\n",
    "        if not df_mom_source.empty:\n",
    "            current_ems_val = (\n",
    "                df_current.loc[\"EMS\", metric] if \"EMS\" in df_current.index else np.nan\n",
    "            )\n",
    "            mom_ems_val = (\n",
    "                df_mom_source.loc[\"EMS\", metric]\n",
    "                if \"EMS\" in df_mom_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"ç¯æ¯”\"), \"EMS\"] = current_ems_val - mom_ems_val\n",
    "            current_kuaibao_val = (\n",
    "                df_current.loc[\"å¿«åŒ…\", metric] if \"å¿«åŒ…\" in df_current.index else np.nan\n",
    "            )\n",
    "            mom_kuaibao_val = (\n",
    "                df_mom_source.loc[\"å¿«åŒ…\", metric]\n",
    "                if \"å¿«åŒ…\" in df_mom_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"ç¯æ¯”\"), \"é‚®æ”¿å¿«åŒ…\"] = (\n",
    "                current_kuaibao_val - mom_kuaibao_val\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"ç¯æ¯”\"), \"è¡Œä¸šå‡å€¼\"] = industry_mean_current.get(\n",
    "                metric\n",
    "            ) - industry_mean_mom.get(metric)\n",
    "            df_sheet1.loc[(metric, \"ç¯æ¯”\"), \"è¡Œä¸šæœ€ä¼˜\"] = industry_best_current.get(\n",
    "                metric\n",
    "            ) - industry_best_mom.get(metric)\n",
    "            df_sheet1.loc[(metric, \"ç¯æ¯”\"), \"EMSæ’å\"] = (\n",
    "                df_mom_source.loc[\"EMS\", rank_col]\n",
    "                if \"EMS\" in df_mom_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"ç¯æ¯”\"), \"é‚®æ”¿å¿«åŒ…æ’å\"] = (\n",
    "                df_mom_source.loc[\"å¿«åŒ…\", rank_col]\n",
    "                if \"å¿«åŒ…\" in df_mom_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "        if not df_yoy_source.empty:\n",
    "            yoy_ems_val = (\n",
    "                df_yoy_source.loc[\"EMS\", metric]\n",
    "                if \"EMS\" in df_yoy_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"åŒæ¯”\"), \"EMS\"] = current_ems_val - yoy_ems_val\n",
    "            yoy_kuaibao_val = (\n",
    "                df_yoy_source.loc[\"å¿«åŒ…\", metric]\n",
    "                if \"å¿«åŒ…\" in df_yoy_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"åŒæ¯”\"), \"é‚®æ”¿å¿«åŒ…\"] = (\n",
    "                current_kuaibao_val - yoy_kuaibao_val\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"åŒæ¯”\"), \"è¡Œä¸šå‡å€¼\"] = industry_mean_current.get(\n",
    "                metric\n",
    "            ) - industry_mean_yoy.get(metric)\n",
    "            df_sheet1.loc[(metric, \"åŒæ¯”\"), \"è¡Œä¸šæœ€ä¼˜\"] = industry_best_current.get(\n",
    "                metric\n",
    "            ) - industry_best_yoy.get(metric)\n",
    "            df_sheet1.loc[(metric, \"åŒæ¯”\"), \"EMSæ’å\"] = (\n",
    "                df_yoy_source.loc[\"EMS\", rank_col]\n",
    "                if \"EMS\" in df_yoy_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "            df_sheet1.loc[(metric, \"åŒæ¯”\"), \"é‚®æ”¿å¿«åŒ…æ’å\"] = (\n",
    "                df_yoy_source.loc[\"å¿«åŒ…\", rank_col]\n",
    "                if \"å¿«åŒ…\" in df_yoy_source.index\n",
    "                else np.nan\n",
    "            )\n",
    "\n",
    "    print(\"  - [Sheet 2/3] æ­£åœ¨ç”Ÿæˆ 'EMSåŒç¯æ¯”'...\")\n",
    "    df_sheet2_ems = create_city_comparison_sheet(\n",
    "        \"EMS\", df_current_raw, df_mom_raw, df_yoy_raw\n",
    "    )\n",
    "    print(\"  - [Sheet 3/3] æ­£åœ¨ç”Ÿæˆ 'é‚®æ”¿å¿«åŒ…åŒç¯æ¯”'...\")\n",
    "    df_sheet3_kb = create_city_comparison_sheet(\n",
    "        \"å¿«åŒ…\", df_current_raw, df_mom_raw, df_yoy_raw\n",
    "    )\n",
    "\n",
    "    print(\"  - æ­£åœ¨æ ¼å¼åŒ–è¡¨æ ¼å¹¶ä¿å­˜è‡³åŒä¸€ä¸ªExcelæ–‡ä»¶...\")\n",
    "    output_file_path = (\n",
    "        POSTAL_OUTPUT_DIR / f\"3_åˆ†ç¯èŠ‚æ—¶é™åŠæ’å_{CURRENT_YEAR_MONTH}.xlsx\"\n",
    "    )\n",
    "    with pd.ExcelWriter(output_file_path, engine=\"xlsxwriter\") as writer:\n",
    "        df_sheet1.to_excel(writer, sheet_name=\"åˆ†ç¯èŠ‚æ—¶é™åˆ†æ\", na_rep=\"-\")\n",
    "        df_sheet2_ems.to_excel(writer, sheet_name=\"EMSåŒç¯æ¯”\", index=False, na_rep=\"-\")\n",
    "        df_sheet3_kb.to_excel(\n",
    "            writer, sheet_name=\"é‚®æ”¿å¿«åŒ…åŒç¯æ¯”\", index=False, na_rep=\"-\"\n",
    "        )\n",
    "\n",
    "        workbook = writer.book\n",
    "        float_format, int_format, percent_format = (\n",
    "            workbook.add_format({\"num_format\": \"0.00\"}),\n",
    "            workbook.add_format({\"num_format\": \"0\"}),\n",
    "            workbook.add_format({\"num_format\": \"0.00%\"}),\n",
    "        )\n",
    "        worksheet1 = writer.sheets[\"åˆ†ç¯èŠ‚æ—¶é™åˆ†æ\"]\n",
    "        worksheet1.set_column(\"C:F\", 12, float_format)\n",
    "        worksheet1.set_column(\"G:H\", 12, int_format)\n",
    "        worksheet1.set_column(\"A:B\", 18)\n",
    "\n",
    "        for sheet_name in [\"EMSåŒç¯æ¯”\", \"é‚®æ”¿å¿«åŒ…åŒç¯æ¯”\"]:\n",
    "            if sheet_name not in writer.sheets:\n",
    "                continue\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            worksheet.set_column(\"A:A\", 15)\n",
    "            df_to_format = df_sheet2_ems if \"EMS\" in sheet_name else df_sheet3_kb\n",
    "            if df_to_format.empty:\n",
    "                continue\n",
    "            for i, col_name in enumerate(df_to_format.columns[1:], 1):\n",
    "                if \"å¹…åº¦\" in col_name:\n",
    "                    worksheet.set_column(i, i, 18, percent_format)\n",
    "                else:\n",
    "                    worksheet.set_column(i, i, 18, float_format)\n",
    "    print(f\"\\nğŸ‰ æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: {output_file_path}\")\n",
    "\n",
    "\n",
    "# --- 5. ä¸»æ‰§è¡Œå…¥å£ ---\n",
    "if __name__ == \"__main__\":\n",
    "    generate_segment_times_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹ç”Ÿæˆ è¡¨4-7 åˆ†å…¬é‡Œæ®µæ—¶é™åŠæ’å...\n",
      "  - æ­£åœ¨æå–æ‰€æœ‰å‘¨æœŸçš„åŸºç¡€æŒ‡æ ‡æ•°æ®...\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š æ­£åœ¨å¤„ç†å…¬é‡Œæ®µ: 0-600 (Sheet: è¡¨4ï¼š600å…¬é‡Œä»¥ä¸‹ï¼ˆå«600å…¬é‡Œï¼‰)\n",
      "    - âœ… Sheet 'è¡¨4ï¼š600å…¬é‡Œä»¥ä¸‹ï¼ˆå«600å…¬é‡Œï¼‰' ç”ŸæˆæˆåŠŸã€‚\n",
      "ğŸ“Š æ­£åœ¨å¤„ç†å…¬é‡Œæ®µ: 600-1500 (Sheet: è¡¨5ï¼š600-1500å…¬é‡Œï¼ˆå«1500å…¬é‡Œï¼‰)\n",
      "    - âœ… Sheet 'è¡¨5ï¼š600-1500å…¬é‡Œï¼ˆå«1500å…¬é‡Œï¼‰' ç”ŸæˆæˆåŠŸã€‚\n",
      "ğŸ“Š æ­£åœ¨å¤„ç†å…¬é‡Œæ®µ: 1500-2500 (Sheet: è¡¨6ï¼š1500-2500å…¬é‡Œï¼ˆå«2500å…¬é‡Œï¼‰)\n",
      "    - âœ… Sheet 'è¡¨6ï¼š1500-2500å…¬é‡Œï¼ˆå«2500å…¬é‡Œï¼‰' ç”ŸæˆæˆåŠŸã€‚\n",
      "ğŸ“Š æ­£åœ¨å¤„ç†å…¬é‡Œæ®µ: 2500ä»¥ä¸Š (Sheet: è¡¨7ï¼š2500å…¬é‡Œä»¥ä¸Š)\n",
      "    - âœ… Sheet 'è¡¨7ï¼š2500å…¬é‡Œä»¥ä¸Š' ç”ŸæˆæˆåŠŸã€‚\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ‰ é‚®æ”¿æœˆæŠ¥ è¡¨4-7 åˆ†å…¬é‡Œæ®µæ—¶é™åŠæ’å å·²æˆåŠŸä¿å­˜è‡³: /Users/lava/Documents/å›½å®¶é‚®æ”¿å±€å‘å±•ç ”ç©¶ä¸­å¿ƒå®ä¹ /python_data_analysis/æŠ¥å‘Šæ•°æ®/è¾“å‡º/3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼/4_åˆ†å…¬é‡Œæ—¶é™åŠæ’å_202506.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3.4: é‚®æ”¿æŠ¥å‘Šæ‰€éœ€è¡¨æ ¼ç”Ÿæˆ è¡¨4-7 åˆ†å…¬é‡Œæ®µæ—¶é™åŠæ’å\n",
    "# ==============================================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. å…¨å±€é…ç½® ---\n",
    "ROOT_PATH = Path.cwd()\n",
    "POSTAL_OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼\"\n",
    "POSTAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_file_paths(period_label):\n",
    "    if period_label == \"æœ¬æœŸ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"data_analysis_result\"\n",
    "        }\n",
    "    elif period_label == \"ä¸Šæœˆ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{PREVIOUS_YEAR_MONTH}\"\n",
    "            / f\"data_analysis_result_{PREVIOUS_YEAR_MONTH}\"\n",
    "        }\n",
    "    elif period_label == \"å»å¹´åŒæœŸ\":\n",
    "        return {\n",
    "            \"data_analysis\": ROOT_PATH\n",
    "            / \"æŠ¥å‘Šæ•°æ®\"\n",
    "            / \"è¾“å…¥\"\n",
    "            / \"historical_data\"\n",
    "            / f\"{LAST_YEAR_MONTH}\"\n",
    "            / f\"data_analysis_result_{LAST_YEAR_MONTH}\"\n",
    "        }\n",
    "    return {}\n",
    "\n",
    "\n",
    "COMPANY_FILE_MAP = {\n",
    "    \"EMS\": \"EMS\",\n",
    "    \"å¿«åŒ…\": \"é‚®æ”¿\",\n",
    "    \"ä¸­é€š\": \"ä¸­é€š\",\n",
    "    \"åœ†é€š\": \"åœ†é€š\",\n",
    "    \"æå…”\": \"æå…”\",\n",
    "    \"ç”³é€š\": \"ç”³é€š\",\n",
    "    \"éŸµè¾¾\": \"éŸµè¾¾\",\n",
    "    \"é¡ºä¸°\": \"é¡ºä¸°\",\n",
    "    \"äº¬ä¸œ\": \"äº¬ä¸œ\",\n",
    "    \"å¾·é‚¦\": \"å¾·é‚¦\",\n",
    "}\n",
    "# ç”¨äºè¡Œä¸šå¯¹æ¯”çš„å…¬å¸åˆ—è¡¨ï¼Œæ˜ç¡®æ’é™¤'å¿«åŒ…'\n",
    "COMPANIES_FOR_INDUSTRY_COMPARISON = [c for c in COMPANY_FILE_MAP.keys() if c != \"å¿«åŒ…\"]\n",
    "\n",
    "METRICS_OF_INTEREST = [\n",
    "    \"å…¨ç¨‹æ—¶é™\",\n",
    "    \"å¯„å‡ºåœ°å¤„ç†æ—¶é™\",\n",
    "    \"è¿è¾“æ—¶é™\",\n",
    "    \"å¯„è¾¾åœ°å¤„ç†æ—¶é™\",\n",
    "    \"æŠ•é€’æ—¶é™\",\n",
    "]\n",
    "RANK_SUFFIX, SHEET_NAME = \"-æ’å\", \"åŸºç¡€æŒ‡æ ‡\"\n",
    "DISTANCE_COLS = {\n",
    "    \"è¡¨4ï¼š600å…¬é‡Œä»¥ä¸‹ï¼ˆå«600å…¬é‡Œï¼‰\": {\"col_name\": \"0-600\", \"label\": \"0-600\"},\n",
    "    \"è¡¨5ï¼š600-1500å…¬é‡Œï¼ˆå«1500å…¬é‡Œï¼‰\": {\"col_name\": \"600-1500\", \"label\": \"600-1500\"},\n",
    "    \"è¡¨6ï¼š1500-2500å…¬é‡Œï¼ˆå«2500å…¬é‡Œï¼‰\": {\"col_name\": \"1500-2500\", \"label\": \"1500-2500\"},\n",
    "    \"è¡¨7ï¼š2500å…¬é‡Œä»¥ä¸Š\": {\"col_name\": \"2500ä»¥ä¸Š\", \"label\": \"2500ä»¥ä¸Š\"},\n",
    "}\n",
    "\n",
    "\n",
    "# --- 2. è¾…åŠ©å‡½æ•° ---\n",
    "def extract_metrics_from_folder(folder_path, sheet_name=SHEET_NAME):\n",
    "    if not folder_path or not folder_path.is_dir():\n",
    "        return {}\n",
    "    all_company_data = {}\n",
    "    for f_path in folder_path.glob(\"*.xlsx\"):\n",
    "        company_name_standard = next(\n",
    "            (\n",
    "                std_name\n",
    "                for std_name, prefix in COMPANY_FILE_MAP.items()\n",
    "                if prefix in f_path.name\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if not company_name_standard:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_excel(f_path, sheet_name=sheet_name, index_col=\"é¡¹ç›®\")\n",
    "            df.columns = df.columns.str.strip()\n",
    "            all_company_data[company_name_standard] = df\n",
    "        except Exception:\n",
    "            continue\n",
    "    return all_company_data\n",
    "\n",
    "\n",
    "def calculate_special_ranks(series):\n",
    "    ranks = {}\n",
    "    if \"EMS\" in series.index:\n",
    "        ranks[\"EMS\"] = (\n",
    "            series.drop(index=\"å¿«åŒ…\", errors=\"ignore\")\n",
    "            .rank(method=\"min\", ascending=True)\n",
    "            .get(\"EMS\")\n",
    "        )\n",
    "    if \"å¿«åŒ…\" in series.index:\n",
    "        ranks[\"å¿«åŒ…\"] = (\n",
    "            series.drop(index=\"EMS\", errors=\"ignore\")\n",
    "            .rank(method=\"min\", ascending=True)\n",
    "            .get(\"å¿«åŒ…\")\n",
    "        )\n",
    "    return ranks\n",
    "\n",
    "\n",
    "# --- 3. æ ¸å¿ƒæ‰§è¡Œå‡½æ•° ---\n",
    "def generate_distance_segmented_tables():\n",
    "    print(\"ğŸš€ å¼€å§‹ç”Ÿæˆ è¡¨4-7 åˆ†å…¬é‡Œæ®µæ—¶é™åŠæ’å...\")\n",
    "    print(\"  - æ­£åœ¨æå–æ‰€æœ‰å‘¨æœŸçš„åŸºç¡€æŒ‡æ ‡æ•°æ®...\")\n",
    "    current_data = extract_metrics_from_folder(\n",
    "        get_file_paths(\"æœ¬æœŸ\").get(\"data_analysis\")\n",
    "    )\n",
    "    mom_data = extract_metrics_from_folder(get_file_paths(\"ä¸Šæœˆ\").get(\"data_analysis\"))\n",
    "    yoy_data = extract_metrics_from_folder(\n",
    "        get_file_paths(\"å»å¹´åŒæœŸ\").get(\"data_analysis\")\n",
    "    )\n",
    "\n",
    "    if not current_data:\n",
    "        print(\n",
    "            f\"  - âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°å½“æœŸæ•°æ® (æ¥è‡ª data_analysis_result), æ— æ³•ç”Ÿæˆè¡¨æ ¼ã€‚\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    output_file_path = (\n",
    "        POSTAL_OUTPUT_DIR / f\"4_åˆ†å…¬é‡Œæ—¶é™åŠæ’å_{CURRENT_YEAR_MONTH}.xlsx\"\n",
    "    )\n",
    "    with pd.ExcelWriter(output_file_path, engine=\"xlsxwriter\") as writer:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        for sheet_title, segment in DISTANCE_COLS.items():\n",
    "            dist_col = segment[\"col_name\"]\n",
    "            print(f\"ğŸ“Š æ­£åœ¨å¤„ç†å…¬é‡Œæ®µ: {dist_col} (Sheet: {sheet_title})\")\n",
    "\n",
    "            all_metrics_current, all_metrics_mom, all_metrics_yoy = {}, {}, {}\n",
    "            for metric in METRICS_OF_INTEREST:\n",
    "                all_metrics_current[metric] = pd.Series(\n",
    "                    {\n",
    "                        comp: df.loc[metric, dist_col]\n",
    "                        for comp, df in current_data.items()\n",
    "                        if metric in df.index and dist_col in df.columns\n",
    "                    }\n",
    "                )\n",
    "                all_metrics_mom[metric] = pd.Series(\n",
    "                    {\n",
    "                        comp: df.loc[metric, dist_col]\n",
    "                        for comp, df in mom_data.items()\n",
    "                        if metric in df.index and dist_col in df.columns\n",
    "                    }\n",
    "                )\n",
    "                all_metrics_yoy[metric] = pd.Series(\n",
    "                    {\n",
    "                        comp: df.loc[metric, dist_col]\n",
    "                        for comp, df in yoy_data.items()\n",
    "                        if metric in df.index and dist_col in df.columns\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            index_tuples = [\n",
    "                (metric, p)\n",
    "                for metric in METRICS_OF_INTEREST\n",
    "                for p in [CURRENT_MONTH_DISPLAY, \"ç¯æ¯”\", \"åŒæ¯”\"]\n",
    "            ]\n",
    "            multi_index = pd.MultiIndex.from_tuples(\n",
    "                index_tuples, names=[f\"æŒ‡æ ‡{segment['label']}\", \"\"]\n",
    "            )\n",
    "            final_df = pd.DataFrame(\n",
    "                index=multi_index,\n",
    "                columns=[\n",
    "                    \"EMS\",\n",
    "                    \"é‚®æ”¿å¿«åŒ…\",\n",
    "                    \"è¡Œä¸šå‡å€¼\",\n",
    "                    \"è¡Œä¸šæœ€ä¼˜\",\n",
    "                    \"EMSæ’å\",\n",
    "                    \"é‚®æ”¿å¿«åŒ…æ’å\",\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            for metric in METRICS_OF_INTEREST:\n",
    "                series_current, series_mom, series_yoy = (\n",
    "                    all_metrics_current.get(metric, pd.Series(dtype=float)),\n",
    "                    all_metrics_mom.get(metric, pd.Series(dtype=float)),\n",
    "                    all_metrics_yoy.get(metric, pd.Series(dtype=float)),\n",
    "                )\n",
    "                if series_current.empty:\n",
    "                    continue\n",
    "\n",
    "                ranks_current, ranks_mom, ranks_yoy = (\n",
    "                    calculate_special_ranks(series_current),\n",
    "                    calculate_special_ranks(series_mom),\n",
    "                    calculate_special_ranks(series_yoy),\n",
    "                )\n",
    "\n",
    "                # ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "                series_current_industry = series_current.drop(\n",
    "                    labels=[\"å¿«åŒ…\"], errors=\"ignore\"\n",
    "                )\n",
    "                industry_mean_current, industry_best_current = (\n",
    "                    series_current_industry.mean(),\n",
    "                    series_current_industry.min(),\n",
    "                )\n",
    "\n",
    "                series_mom_industry = series_mom.drop(labels=[\"å¿«åŒ…\"], errors=\"ignore\")\n",
    "                industry_mean_mom, industry_best_mom = (\n",
    "                    series_mom_industry.mean(),\n",
    "                    series_mom_industry.min(),\n",
    "                )\n",
    "\n",
    "                series_yoy_industry = series_yoy.drop(labels=[\"å¿«åŒ…\"], errors=\"ignore\")\n",
    "                industry_mean_yoy, industry_best_yoy = (\n",
    "                    series_yoy_industry.mean(),\n",
    "                    series_yoy_industry.min(),\n",
    "                )\n",
    "\n",
    "                # å¡«å……æœ¬æœŸæ•°æ®\n",
    "                final_df.loc[(metric, CURRENT_MONTH_DISPLAY), \"EMS\"] = (\n",
    "                    series_current.get(\"EMS\")\n",
    "                )\n",
    "                final_df.loc[(metric, CURRENT_MONTH_DISPLAY), \"é‚®æ”¿å¿«åŒ…\"] = (\n",
    "                    series_current.get(\"å¿«åŒ…\")\n",
    "                )\n",
    "                final_df.loc[(metric, CURRENT_MONTH_DISPLAY), \"è¡Œä¸šå‡å€¼\"] = (\n",
    "                    industry_mean_current\n",
    "                )\n",
    "                final_df.loc[(metric, CURRENT_MONTH_DISPLAY), \"è¡Œä¸šæœ€ä¼˜\"] = (\n",
    "                    industry_best_current\n",
    "                )\n",
    "                final_df.loc[(metric, CURRENT_MONTH_DISPLAY), \"EMSæ’å\"] = (\n",
    "                    ranks_current.get(\"EMS\")\n",
    "                )\n",
    "                final_df.loc[(metric, CURRENT_MONTH_DISPLAY), \"é‚®æ”¿å¿«åŒ…æ’å\"] = (\n",
    "                    ranks_current.get(\"å¿«åŒ…\")\n",
    "                )\n",
    "\n",
    "                # å¡«å……ç¯æ¯”æ•°æ®\n",
    "                final_df.loc[(metric, \"ç¯æ¯”\"), \"EMS\"] = series_current.get(\n",
    "                    \"EMS\", np.nan\n",
    "                ) - series_mom.get(\"EMS\", np.nan)\n",
    "                final_df.loc[(metric, \"ç¯æ¯”\"), \"é‚®æ”¿å¿«åŒ…\"] = series_current.get(\n",
    "                    \"å¿«åŒ…\", np.nan\n",
    "                ) - series_mom.get(\"å¿«åŒ…\", np.nan)\n",
    "                final_df.loc[(metric, \"ç¯æ¯”\"), \"è¡Œä¸šå‡å€¼\"] = (\n",
    "                    industry_mean_current - industry_mean_mom\n",
    "                )\n",
    "                final_df.loc[(metric, \"ç¯æ¯”\"), \"è¡Œä¸šæœ€ä¼˜\"] = (\n",
    "                    industry_best_current - industry_best_mom\n",
    "                )\n",
    "                final_df.loc[(metric, \"ç¯æ¯”\"), \"EMSæ’å\"] = ranks_mom.get(\"EMS\")\n",
    "                final_df.loc[(metric, \"ç¯æ¯”\"), \"é‚®æ”¿å¿«åŒ…æ’å\"] = ranks_mom.get(\"å¿«åŒ…\")\n",
    "\n",
    "                # å¡«å……åŒæ¯”æ•°æ®\n",
    "                final_df.loc[(metric, \"åŒæ¯”\"), \"EMS\"] = series_current.get(\n",
    "                    \"EMS\", np.nan\n",
    "                ) - series_yoy.get(\"EMS\", np.nan)\n",
    "                final_df.loc[(metric, \"åŒæ¯”\"), \"é‚®æ”¿å¿«åŒ…\"] = series_current.get(\n",
    "                    \"å¿«åŒ…\", np.nan\n",
    "                ) - series_yoy.get(\"å¿«åŒ…\", np.nan)\n",
    "                final_df.loc[(metric, \"åŒæ¯”\"), \"è¡Œä¸šå‡å€¼\"] = (\n",
    "                    industry_mean_current - industry_mean_yoy\n",
    "                )\n",
    "                final_df.loc[(metric, \"åŒæ¯”\"), \"è¡Œä¸šæœ€ä¼˜\"] = (\n",
    "                    industry_best_current - industry_best_yoy\n",
    "                )\n",
    "                final_df.loc[(metric, \"åŒæ¯”\"), \"EMSæ’å\"] = ranks_yoy.get(\"EMS\")\n",
    "                final_df.loc[(metric, \"åŒæ¯”\"), \"é‚®æ”¿å¿«åŒ…æ’å\"] = ranks_yoy.get(\"å¿«åŒ…\")\n",
    "\n",
    "            final_df.to_excel(writer, sheet_name=sheet_title, na_rep=\"-\")\n",
    "            worksheet, workbook = writer.sheets[sheet_title], writer.book\n",
    "            float_format, int_format = (\n",
    "                workbook.add_format({\"num_format\": \"0.00\", \"align\": \"center\"}),\n",
    "                workbook.add_format({\"num_format\": \"0\", \"align\": \"center\"}),\n",
    "            )\n",
    "            worksheet.set_column(\"C:F\", 12, float_format)\n",
    "            worksheet.set_column(\"G:H\", 15, int_format)\n",
    "            worksheet.set_column(\"A:B\", 18)\n",
    "            print(f\"    - âœ… Sheet '{sheet_title}' ç”ŸæˆæˆåŠŸã€‚\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"\\nğŸ‰ é‚®æ”¿æœˆæŠ¥ è¡¨4-7 åˆ†å…¬é‡Œæ®µæ—¶é™åŠæ’å å·²æˆåŠŸä¿å­˜è‡³: {output_file_path}\")\n",
    "\n",
    "\n",
    "# --- 4. ä¸»æ‰§è¡Œå…¥å£ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # å‡è®¾æŠ¥å‘Šå‘¨æœŸå˜é‡å·²å®šä¹‰\n",
    "    # CURRENT_YEAR_MONTH, PREVIOUS_YEAR_MONTH, LAST_YEAR_MONTH, CURRENT_MONTH_DISPLAY\n",
    "    generate_distance_segmented_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- å¼€å§‹ç”Ÿæˆ 5_ä¸‰å¤§ç»æµåœˆåŸå¸‚äº’å¯„æ—¶é™ æŠ¥å‘Š ---\n",
      "\n",
      "[æ­¥éª¤1/4] æ­£åœ¨åŠ è½½å¹¶å¤„ç†å„æ—¶æœŸæ•°æ®...\n",
      "  - æ­£åœ¨ä»æ–‡ä»¶ 'åˆ†ææ€»æŠ¥å‘Š.xlsx' çš„ sheet 'æœ€ç»ˆçº¿è·¯æ˜ç»†ç»“æœ' è¯»å–æ•°æ®...\n",
      "  - æ­£åœ¨ä»æ–‡ä»¶ 'åˆ†ææ€»æŠ¥å‘Š_202505.xlsx' çš„ sheet 'æœ€ç»ˆçº¿è·¯æ˜ç»†ç»“æœ' è¯»å–æ•°æ®...\n",
      "  - æ­£åœ¨ä»æ–‡ä»¶ 'åˆ†ææ€»æŠ¥å‘Š_202406.xlsx' çš„ sheet 'æœ€ç»ˆçº¿è·¯æ˜ç»†ç»“æœ' è¯»å–æ•°æ®...\n",
      "\n",
      "[æ­¥éª¤1/4] æ•°æ®åŠ è½½å¤„ç†å®Œæˆã€‚\n",
      "\n",
      "[æ­¥éª¤2/4] æ­£åœ¨ç”Ÿæˆå„Sheetå¹¶å†™å…¥åˆ°: /Users/lava/Documents/å›½å®¶é‚®æ”¿å±€å‘å±•ç ”ç©¶ä¸­å¿ƒå®ä¹ /python_data_analysis/æŠ¥å‘Šæ•°æ®/è¾“å‡º/3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼/5_ä¸‰å¤§ç»æµåœˆåŸå¸‚äº’å¯„æ—¶é™.xlsx\n",
      "  - Sheet 'è¡¨8ï¼šäº¬æ´¥å†€åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™' å·²ç”Ÿæˆ.\n",
      "  - Sheet 'è¡¨9ï¼šé•¿ä¸‰è§’åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™' å·²ç”Ÿæˆ.\n",
      "  - Sheet 'è¡¨10ï¼šç ä¸‰è§’åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™' å·²ç”Ÿæˆ.\n",
      "  - Sheet 'è¡¨11ï¼šä¸‰å¤§ç»æµåœˆä¹‹é—´äº’å¯„å…¨ç¨‹æ—¶é™' å·²ç”Ÿæˆ.\n",
      "[æ­¥éª¤2/4] ExcelåŸºç¡€æ–‡ä»¶å†™å…¥å®Œæˆã€‚\n",
      "\n",
      "[æ­¥éª¤3/4] æ­£åœ¨å¯¹Excelæ–‡ä»¶è¿›è¡Œæœ€ç»ˆæ ¼å¼åŒ–...\n",
      "  - Sheet 'è¡¨8ï¼šäº¬æ´¥å†€åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™' æ ¼å¼åŒ–å®Œæˆ.\n",
      "  - Sheet 'è¡¨9ï¼šé•¿ä¸‰è§’åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™' æ ¼å¼åŒ–å®Œæˆ.\n",
      "  - Sheet 'è¡¨10ï¼šç ä¸‰è§’åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™' æ ¼å¼åŒ–å®Œæˆ.\n",
      "  - Sheet 'è¡¨11ï¼šä¸‰å¤§ç»æµåœˆä¹‹é—´äº’å¯„å…¨ç¨‹æ—¶é™' æ ¼å¼åŒ–å®Œæˆ.\n",
      "[æ­¥éª¤4/4] æ ¼å¼åŒ–å®Œæˆå¹¶å·²ä¿å­˜ã€‚\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ä»»åŠ¡å®Œæˆï¼æŠ¥è¡¨å·²æˆåŠŸç”Ÿæˆã€‚\n",
      "æ–‡ä»¶è·¯å¾„: /Users/lava/Documents/å›½å®¶é‚®æ”¿å±€å‘å±•ç ”ç©¶ä¸­å¿ƒå®ä¹ /python_data_analysis/æŠ¥å‘Šæ•°æ®/è¾“å‡º/3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼/5_ä¸‰å¤§ç»æµåœˆåŸå¸‚äº’å¯„æ—¶é™.xlsx\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3.5: é‚®æ”¿æŠ¥å‘Šæ‰€éœ€è¡¨æ ¼ç”Ÿæˆ è¡¨8-11 ä¸‰å¤§ç»æµåœˆåŸå¸‚äº’å¯„æ—¶é™\n",
    "# ==============================================================================\n",
    "# ç¡®ä¿åœ¨è„šæœ¬å¼€å¤´æœ‰å¿…è¦çš„å¯¼å…¥\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment, Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# --- 1. å…¨å±€é…ç½® ---\n",
    "try:\n",
    "    ROOT_PATH = Path.cwd()\n",
    "    POSTAL_OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼\"\n",
    "    POSTAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "except NameError:\n",
    "    ROOT_PATH = Path(\".\")\n",
    "    POSTAL_OUTPUT_DIR = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"3_é‚®æ”¿æŠ¥å‘Šè¡¨æ ¼\"\n",
    "    POSTAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "current_file_path = ROOT_PATH / \"æŠ¥å‘Šæ•°æ®\" / \"è¾“å‡º\" / \"åˆ†ææ€»æŠ¥å‘Š.xlsx\"\n",
    "prev_file_path = (\n",
    "    ROOT_PATH\n",
    "    / \"æŠ¥å‘Šæ•°æ®\"\n",
    "    / \"è¾“å…¥\"\n",
    "    / \"historical_data\"\n",
    "    / f\"{PREVIOUS_YEAR_MONTH}\"\n",
    "    / f\"åˆ†ææ€»æŠ¥å‘Š_{PREVIOUS_YEAR_MONTH}.xlsx\"\n",
    ")\n",
    "last_year_file_path = (\n",
    "    ROOT_PATH\n",
    "    / \"æŠ¥å‘Šæ•°æ®\"\n",
    "    / \"è¾“å…¥\"\n",
    "    / \"historical_data\"\n",
    "    / f\"{LAST_YEAR_MONTH}\"\n",
    "    / f\"åˆ†ææ€»æŠ¥å‘Š_{LAST_YEAR_MONTH}.xlsx\"\n",
    ")\n",
    "DATA_SHEET_NAME = \"æœ€ç»ˆçº¿è·¯æ˜ç»†ç»“æœ\"\n",
    "\n",
    "ALL_COMPANIES = [\n",
    "    \"EMS\",\n",
    "    \"é‚®æ”¿å¿«åŒ…\",\n",
    "    \"ä¸­é€š\",\n",
    "    \"åœ†é€š\",\n",
    "    \"æå…”\",\n",
    "    \"ç”³é€š\",\n",
    "    \"éŸµè¾¾\",\n",
    "    \"é¡ºä¸°\",\n",
    "    \"äº¬ä¸œ\",\n",
    "    \"å¾·é‚¦\",\n",
    "]\n",
    "# ç”¨äºè¡Œä¸šå¯¹æ¯”çš„å…¬å¸åˆ—è¡¨ï¼Œæ˜ç¡®æ’é™¤'é‚®æ”¿å¿«åŒ…'\n",
    "COMPANIES_FOR_INDUSTRY_COMPARISON = [c for c in ALL_COMPANIES if c != \"é‚®æ”¿å¿«åŒ…\"]\n",
    "METRICS_OF_INTEREST = [\n",
    "    \"å…¨ç¨‹æ—¶é™\",\n",
    "    \"å¯„å‡ºåœ°å¤„ç†æ—¶é™\",\n",
    "    \"è¿è¾“æ—¶é™\",\n",
    "    \"å¯„è¾¾åœ°å¤„ç†æ—¶é™\",\n",
    "    \"æŠ•é€’æ—¶é™\",\n",
    "]\n",
    "COMPANY_FILE_MAP = {\n",
    "    \"é‚®æ”¿å¿«åŒ…\": \"å¿«åŒ…\",\n",
    "    **{c: c for c in ALL_COMPANIES if c != \"é‚®æ”¿å¿«åŒ…\"},\n",
    "}\n",
    "NUMERIC_COLS, RANK_COLS = (\n",
    "    [\"EMS\", \"é‚®æ”¿å¿«åŒ…\", \"è¡Œä¸šå‡å€¼\", \"è¡Œä¸šæœ€ä¼˜\"],\n",
    "    [\"EMSæ’å\", \"é‚®æ”¿å¿«åŒ…æ’å\"],\n",
    ")\n",
    "FINAL_COLS = NUMERIC_COLS + RANK_COLS\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# --- 2. æ ¸å¿ƒæ•°æ®å¤„ç†å‡½æ•° ---\n",
    "# =================================================================================\n",
    "def calculate_metrics_from_report(file_path, sheet_name):\n",
    "    if not file_path.exists():\n",
    "        print(f\"!! é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        print(f\"  - æ­£åœ¨ä»æ–‡ä»¶ '{file_path.name}' çš„ sheet '{sheet_name}' è¯»å–æ•°æ®...\")\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        df.columns = df.columns.str.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"!! é”™è¯¯: è¯»å–æ–‡ä»¶ '{file_path.name}' çš„ sheet '{sheet_name}' å¤±è´¥: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    if \"åŸå¸‚åœˆ\" not in df.columns:\n",
    "        print(f\"!! ä¸¥é‡é”™è¯¯: åœ¨æ–‡ä»¶ '{file_path.name}' ä¸­æ‰¾ä¸åˆ°å…³é”®åˆ— 'åŸå¸‚åœˆ'ã€‚\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df[\"åŸå¸‚åœˆ\"] = df[\"åŸå¸‚åœˆ\"].astype(str).str.strip()\n",
    "    results = []\n",
    "\n",
    "    # ç»æµåœˆæ•°æ®å¤„ç†\n",
    "    for circle in [\"äº¬æ´¥å†€\", \"é•¿ä¸‰è§’\", \"ç ä¸‰è§’\"]:\n",
    "        df_circle = df[df[\"åŸå¸‚åœˆ\"] == circle]\n",
    "        for metric in METRICS_OF_INTEREST:\n",
    "            metric_results = {\"åŒºåŸŸ\": circle, \"æŒ‡æ ‡\": metric}\n",
    "            company_values = {}\n",
    "            if not df_circle.empty:\n",
    "                for company_name, file_suffix in COMPANY_FILE_MAP.items():\n",
    "                    qty_col, metric_col = (\n",
    "                        f\"å¿«é€’æ•°é‡{file_suffix}\",\n",
    "                        f\"{metric}{file_suffix}\",\n",
    "                    )\n",
    "                    if qty_col in df_circle.columns and metric_col in df_circle.columns:\n",
    "                        subset = df_circle[[qty_col, metric_col]].copy()\n",
    "                        subset[qty_col] = pd.to_numeric(\n",
    "                            subset[qty_col], errors=\"coerce\"\n",
    "                        ).fillna(0)\n",
    "                        subset[metric_col] = pd.to_numeric(\n",
    "                            subset[metric_col], errors=\"coerce\"\n",
    "                        )\n",
    "                        total_qty = subset[qty_col].sum()\n",
    "                        if total_qty > 0:\n",
    "                            company_values[company_name] = (\n",
    "                                subset[metric_col].fillna(0) * subset[qty_col]\n",
    "                            ).sum() / total_qty\n",
    "            for company in ALL_COMPANIES:\n",
    "                metric_results[company] = company_values.get(company, np.nan)\n",
    "            valid_values = pd.Series(company_values).dropna()\n",
    "            # (ä¿®æ”¹) ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "            industry_values = valid_values.drop(labels=[\"é‚®æ”¿å¿«åŒ…\"], errors=\"ignore\")\n",
    "            metric_results.update(\n",
    "                {\n",
    "                    \"è¡Œä¸šå‡å€¼\": industry_values.mean()\n",
    "                    if not industry_values.empty\n",
    "                    else np.nan,\n",
    "                    \"è¡Œä¸šæœ€ä¼˜\": industry_values.min()\n",
    "                    if not industry_values.empty\n",
    "                    else np.nan,\n",
    "                    \"EMSæ’å\": valid_values.drop(\"é‚®æ”¿å¿«åŒ…\", errors=\"ignore\")\n",
    "                    .rank(method=\"min\")\n",
    "                    .get(\"EMS\", np.nan)\n",
    "                    if not valid_values.empty\n",
    "                    else np.nan,\n",
    "                    \"é‚®æ”¿å¿«åŒ…æ’å\": valid_values.drop(\"EMS\", errors=\"ignore\")\n",
    "                    .rank(method=\"min\")\n",
    "                    .get(\"é‚®æ”¿å¿«åŒ…\", np.nan)\n",
    "                    if not valid_values.empty\n",
    "                    else np.nan,\n",
    "                }\n",
    "            )\n",
    "            results.append(metric_results)\n",
    "\n",
    "    # æ±‡æ€»æ•°æ®å¤„ç†\n",
    "    summary_definitions = {\n",
    "        \"å…¨å›½å…¨ç¨‹æ—¶é™\": {\"data\": df, \"calc_metric\": \"å…¨ç¨‹æ—¶é™\"},\n",
    "        \"ç»æµåœˆäº’å¯„å…¨ç¨‹æ—¶é™\": {\n",
    "            \"data\": df[df[\"åŸå¸‚åœˆ\"].isin([\"äº¬æ´¥å†€\", \"é•¿ä¸‰è§’\", \"ç ä¸‰è§’\"])],\n",
    "            \"calc_metric\": \"å…¨ç¨‹æ—¶é™\",\n",
    "        },\n",
    "    }\n",
    "    for label_metric, config in summary_definitions.items():\n",
    "        data_subset, calc_metric = config[\"data\"], config[\"calc_metric\"]\n",
    "        metric_results = {\"åŒºåŸŸ\": \"æ±‡æ€»\", \"æŒ‡æ ‡\": label_metric}\n",
    "        company_values = {}\n",
    "        if not data_subset.empty:\n",
    "            for company_name, file_suffix in COMPANY_FILE_MAP.items():\n",
    "                qty_col, metric_col = (\n",
    "                    f\"å¿«é€’æ•°é‡{file_suffix}\",\n",
    "                    f\"{calc_metric}{file_suffix}\",\n",
    "                )\n",
    "                if qty_col in data_subset.columns and metric_col in data_subset.columns:\n",
    "                    subset = data_subset[[qty_col, metric_col]].copy()\n",
    "                    subset[qty_col] = pd.to_numeric(\n",
    "                        subset[qty_col], errors=\"coerce\"\n",
    "                    ).fillna(0)\n",
    "                    total_qty = subset[qty_col].sum()\n",
    "                    if total_qty > 0:\n",
    "                        subset[metric_col] = pd.to_numeric(\n",
    "                            subset[metric_col], errors=\"coerce\"\n",
    "                        )\n",
    "                        company_values[company_name] = (\n",
    "                            subset[metric_col].fillna(0) * subset[qty_col]\n",
    "                        ).sum() / total_qty\n",
    "        for company in ALL_COMPANIES:\n",
    "            metric_results[company] = company_values.get(company, np.nan)\n",
    "        valid_values = pd.Series(company_values).dropna()\n",
    "        # (ä¿®æ”¹) ä½¿ç”¨ä¸å«'å¿«åŒ…'çš„åˆ—è¡¨è¿›è¡Œè¡Œä¸šå¯¹æ¯”\n",
    "        industry_values = valid_values.drop(labels=[\"é‚®æ”¿å¿«åŒ…\"], errors=\"ignore\")\n",
    "        metric_results.update(\n",
    "            {\n",
    "                \"è¡Œä¸šå‡å€¼\": industry_values.mean()\n",
    "                if not industry_values.empty\n",
    "                else np.nan,\n",
    "                \"è¡Œä¸šæœ€ä¼˜\": industry_values.min()\n",
    "                if not industry_values.empty\n",
    "                else np.nan,\n",
    "                \"EMSæ’å\": valid_values.drop(\"é‚®æ”¿å¿«åŒ…\", errors=\"ignore\")\n",
    "                .rank(method=\"min\")\n",
    "                .get(\"EMS\", np.nan)\n",
    "                if not valid_values.empty\n",
    "                else np.nan,\n",
    "                \"é‚®æ”¿å¿«åŒ…æ’å\": valid_values.drop(\"EMS\", errors=\"ignore\")\n",
    "                .rank(method=\"min\")\n",
    "                .get(\"é‚®æ”¿å¿«åŒ…\", np.nan)\n",
    "                if not valid_values.empty\n",
    "                else np.nan,\n",
    "            }\n",
    "        )\n",
    "        results.append(metric_results)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def create_final_table(\n",
    "    df_current, df_prev, df_last_year, region_name, metrics_list, first_col_name\n",
    "):\n",
    "    if df_current.empty:\n",
    "        return pd.DataFrame()\n",
    "    current_region = df_current[df_current[\"åŒºåŸŸ\"] == region_name].set_index(\"æŒ‡æ ‡\")\n",
    "    prev_region = (\n",
    "        df_prev[df_prev[\"åŒºåŸŸ\"] == region_name].set_index(\"æŒ‡æ ‡\")\n",
    "        if not df_prev.empty\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    year_region = (\n",
    "        df_last_year[df_last_year[\"åŒºåŸŸ\"] == region_name].set_index(\"æŒ‡æ ‡\")\n",
    "        if not df_last_year.empty\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "\n",
    "    data_rows = []\n",
    "    for metric in metrics_list:\n",
    "        if metric not in current_region.index:\n",
    "            continue\n",
    "        current_series = current_region.loc[metric]\n",
    "        prev_series = (\n",
    "            prev_region.loc[metric]\n",
    "            if not prev_region.empty and metric in prev_region.index\n",
    "            else pd.Series(dtype=object)\n",
    "        )\n",
    "        year_series = (\n",
    "            year_region.loc[metric]\n",
    "            if not year_region.empty and metric in year_region.index\n",
    "            else pd.Series(dtype=object)\n",
    "        )\n",
    "        row_current = current_series\n",
    "        row_hb = pd.Series(index=FINAL_COLS, dtype=object)\n",
    "        row_hb[NUMERIC_COLS] = current_series[NUMERIC_COLS] - prev_series[NUMERIC_COLS]\n",
    "        row_hb[RANK_COLS] = prev_series[RANK_COLS]\n",
    "        row_tb = pd.Series(index=FINAL_COLS, dtype=object)\n",
    "        row_tb[NUMERIC_COLS] = current_series[NUMERIC_COLS] - year_series[NUMERIC_COLS]\n",
    "        row_tb[RANK_COLS] = year_series[RANK_COLS]\n",
    "        data_rows.extend([row_current, row_hb, row_tb])\n",
    "\n",
    "    if not data_rows:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(data_rows, columns=FINAL_COLS)\n",
    "    index_tuples = []\n",
    "    for metric in metrics_list:\n",
    "        if metric in current_region.index:\n",
    "            index_tuples.extend(\n",
    "                [(metric, CURRENT_MONTH_DISPLAY), (metric, \"ç¯æ¯”\"), (metric, \"åŒæ¯”\")]\n",
    "            )\n",
    "    df.index = pd.MultiIndex.from_tuples(index_tuples, names=[first_col_name, \"æŒ‡æ ‡\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_excel_sheet(ws, num_format=\"0.00\", rank_format=\"0\"):\n",
    "    if ws.max_row <= 1:\n",
    "        return\n",
    "    for row in ws.iter_rows(min_row=1):\n",
    "        for cell in row:\n",
    "            if cell.row == 1:\n",
    "                cell.font, cell.alignment = (\n",
    "                    Font(bold=True),\n",
    "                    Alignment(horizontal=\"center\", vertical=\"center\"),\n",
    "                )\n",
    "                continue\n",
    "            cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "            if cell.column in [3, 4, 5, 6]:\n",
    "                cell.number_format = num_format\n",
    "            elif cell.column in [7, 8]:\n",
    "                if pd.isna(cell.value):\n",
    "                    cell.value = \"-\"\n",
    "                else:\n",
    "                    cell.number_format = rank_format\n",
    "    start_row = 2\n",
    "    for r in range(3, ws.max_row + 2):\n",
    "        if r > ws.max_row or ws.cell(r, 1).value != ws.cell(start_row, 1).value:\n",
    "            if start_row < r - 1:\n",
    "                ws.merge_cells(\n",
    "                    start_row=start_row, start_column=1, end_row=r - 1, end_column=1\n",
    "                )\n",
    "            ws.cell(start_row, 1).alignment = Alignment(\n",
    "                horizontal=\"center\", vertical=\"center\", wrap_text=True\n",
    "            )\n",
    "            start_row = r\n",
    "    ws.column_dimensions[ws.cell(row=1, column=1).column_letter].width = 20\n",
    "    ws.column_dimensions[ws.cell(row=1, column=2).column_letter].width = 10\n",
    "    for i in range(3, ws.max_column + 1):\n",
    "        ws.column_dimensions[get_column_letter(i)].width = 14\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# --- 3. ä¸»æ‰§è¡Œæµç¨‹ ---\n",
    "# =================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # å‡è®¾æŠ¥å‘Šå‘¨æœŸå˜é‡å·²å®šä¹‰\n",
    "    # CURRENT_YEAR_MONTH, PREVIOUS_YEAR_MONTH, LAST_YEAR_MONTH, CURRENT_MONTH_DISPLAY\n",
    "    print(\"--- å¼€å§‹ç”Ÿæˆ 5_ä¸‰å¤§ç»æµåœˆåŸå¸‚äº’å¯„æ—¶é™ æŠ¥å‘Š ---\")\n",
    "    print(\"\\n[æ­¥éª¤1/4] æ­£åœ¨åŠ è½½å¹¶å¤„ç†å„æ—¶æœŸæ•°æ®...\")\n",
    "    df_current = calculate_metrics_from_report(\n",
    "        current_file_path, sheet_name=DATA_SHEET_NAME\n",
    "    )\n",
    "    df_prev = calculate_metrics_from_report(prev_file_path, sheet_name=DATA_SHEET_NAME)\n",
    "    df_last_year = calculate_metrics_from_report(\n",
    "        last_year_file_path, sheet_name=DATA_SHEET_NAME\n",
    "    )\n",
    "    print(\"\\n[æ­¥éª¤1/4] æ•°æ®åŠ è½½å¤„ç†å®Œæˆã€‚\")\n",
    "    output_filename = POSTAL_OUTPUT_DIR / \"5_ä¸‰å¤§ç»æµåœˆåŸå¸‚äº’å¯„æ—¶é™.xlsx\"\n",
    "    print(f\"\\n[æ­¥éª¤2/4] æ­£åœ¨ç”Ÿæˆå„Sheetå¹¶å†™å…¥åˆ°: {output_filename}\")\n",
    "    with pd.ExcelWriter(output_filename, engine=\"openpyxl\") as writer:\n",
    "        all_sheets = {\n",
    "            \"è¡¨8ï¼šäº¬æ´¥å†€åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™\": (\n",
    "                \"äº¬æ´¥å†€\",\n",
    "                METRICS_OF_INTEREST,\n",
    "                \"äº¬æ´¥å†€åŸå¸‚äº’å¯„\",\n",
    "            ),\n",
    "            \"è¡¨9ï¼šé•¿ä¸‰è§’åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™\": (\n",
    "                \"é•¿ä¸‰è§’\",\n",
    "                METRICS_OF_INTEREST,\n",
    "                \"é•¿ä¸‰è§’åŸå¸‚äº’å¯„\",\n",
    "            ),\n",
    "            \"è¡¨10ï¼šç ä¸‰è§’åŸå¸‚äº’å¯„å…¨ç¨‹æ—¶é™åŠåˆ†ç¯èŠ‚æ—¶é™\": (\n",
    "                \"ç ä¸‰è§’\",\n",
    "                METRICS_OF_INTEREST,\n",
    "                \"ç ä¸‰è§’åŸå¸‚äº’å¯„\",\n",
    "            ),\n",
    "            \"è¡¨11ï¼šä¸‰å¤§ç»æµåœˆä¹‹é—´äº’å¯„å…¨ç¨‹æ—¶é™\": (\n",
    "                \"æ±‡æ€»\",\n",
    "                [\"å…¨å›½å…¨ç¨‹æ—¶é™\", \"ç»æµåœˆäº’å¯„å…¨ç¨‹æ—¶é™\"],\n",
    "                \"ä¸‰å¤§ç»æµåœˆä¹‹é—´äº’å¯„\",\n",
    "            ),\n",
    "        }\n",
    "        for sheet_name, (region, metrics, col_name) in all_sheets.items():\n",
    "            final_df = create_final_table(\n",
    "                df_current, df_prev, df_last_year, region, metrics, col_name\n",
    "            )\n",
    "            final_df.to_excel(writer, sheet_name=sheet_name)\n",
    "            print(f\"  - Sheet '{sheet_name}' å·²ç”Ÿæˆ.\")\n",
    "    print(\"[æ­¥éª¤2/4] ExcelåŸºç¡€æ–‡ä»¶å†™å…¥å®Œæˆã€‚\")\n",
    "\n",
    "    print(\"\\n[æ­¥éª¤3/4] æ­£åœ¨å¯¹Excelæ–‡ä»¶è¿›è¡Œæœ€ç»ˆæ ¼å¼åŒ–...\")\n",
    "    wb = load_workbook(output_filename)\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        format_excel_sheet(ws)\n",
    "        print(f\"  - Sheet '{sheet_name}' æ ¼å¼åŒ–å®Œæˆ.\")\n",
    "    wb.save(output_filename)\n",
    "    print(\"[æ­¥éª¤4/4] æ ¼å¼åŒ–å®Œæˆå¹¶å·²ä¿å­˜ã€‚\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"ğŸ‰ ä»»åŠ¡å®Œæˆï¼æŠ¥è¡¨å·²æˆåŠŸç”Ÿæˆã€‚\")\n",
    "    print(f\"æ–‡ä»¶è·¯å¾„: {output_filename.resolve()}\")\n",
    "    print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
